1670185496.371351888
   RES
121964
1670185496.526634834
   RES
207900
1670185496.679407445
   RES
244180
1670185496.832322593
   RES
291036
1670185496.985199551
   RES
320332
1670185497.138071139
   RES
659980
1670185497.291007255
   RES
766480
1670185497.443704672
   RES
795780
1670185497.596454860
   RES
821124
1670185497.749389758
   RES
849108
1670185497.902303543
   RES
890028
1670185498.055156832
   RES
900852
1670185498.207763005
   RES
951004
1670185498.360624916
   RES
959188
1670185498.513635972
   RES
978.2m
1670185498.666594790
   RES
  1.0g
1670185498.819529855
   RES
  1.0g
1670185498.972643782
   RES
  1.0g
1670185499.125574469
   RES
  1.1g
1670185499.278495445
   RES
  1.1g
1670185499.431627692
   RES
  1.1g
1670185499.584487292
   RES
  1.2g
1670185499.737460031
   RES
  1.2g
1670185499.890365898
   RES
  1.2g
1670185500.043292440
   RES
  1.2g
1670185500.196231006
   RES
  1.3g
1670185500.349073409
   RES
  1.3g
1670185500.501915621
   RES
  1.4g
1670185500.654812347
   RES
  1.4g
1670185500.807777733
   RES
  1.4g
1670185500.960948463
   RES
  1.4g
1670185501.113807467
   RES
  1.5g
1670185501.266552768
   RES
  1.5g
1670185501.419256204
   RES
  1.6g
1670185501.572106378
   RES
  1.6g
1670185501.725081800
   RES
  1.6g
1670185501.878182805
   RES
  1.6g
1670185502.031113334
   RES
  1.6g
1670185502.184151700
   RES
  1.7g
1670185502.337189226
   RES
  1.7g
1670185502.490147218
   RES
  1.8g
1670185502.642959157
   RES
  1.8g
1670185502.796018919
   RES
  1.9g
1670185502.948902527
   RES
  1.9g
1670185503.101905680
   RES
  1.9g
1670185503.255060905
   RES
  1.9g
1670185503.408214894
   RES
  1.9g
1670185503.561853926
   RES
  1.9g
1670185503.714856192
   RES
  2.0g
1670185503.867591456
   RES
  2.0g
1670185504.020415749
   RES
  2.1g
1670185504.173073064
   RES
  2.1g
1670185504.325948447
   RES
  2.1g
1670185504.478721876
   RES
  2.1g
1670185504.631488915
   RES
  2.2g
1670185504.784217518
   RES
  2.2g
1670185504.937021236
   RES
  2.3g
1670185505.089929427
   RES
  2.3g
1670185505.242933586
   RES
  2.3g
1670185505.396092801
   RES
  2.3g
1670185505.549401148
   RES
  2.3g
1670185505.702422336
   RES
  2.3g
1670185505.855295392
   RES
  2.4g
1670185506.008318090
   RES
  2.4g
1670185506.161133053
   RES
  2.5g
1670185506.313967541
   RES
  2.5g
1670185506.466859645
   RES
  2.5g
1670185506.619898614
   RES
  2.5g
1670185506.773030635
   RES
  2.5g
1670185506.926192139
   RES
  2.5g
1670185507.079351722
   RES
  2.6g
1670185507.232458678
   RES
  2.6g
1670185507.385411612
   RES
  2.7g
1670185507.538250987
   RES
  2.7g
1670185507.691103196
   RES
  2.8g
1670185507.844078829
   RES
  2.8g
1670185507.997007269
   RES
  2.8g
1670185508.150039799
   RES
  2.8g
1670185508.303287271
   RES
  2.8g
1670185508.456261555
   RES
  2.8g
1670185508.609340383
   RES
  2.8g
1670185508.762340047
   RES
  2.9g
1670185508.915136794
   RES
  3.0g
1670185509.067999018
   RES
  3.0g
1670185509.220758618
   RES
  3.0g
1670185509.373771617
   RES
  3.0g
1670185509.526869336
   RES
  3.0g
1670185509.679918226
   RES
  3.0g
1670185509.832993965
   RES
  3.0g
1670185509.986172188
   RES
  3.0g
1670185510.139112674
   RES
  3.1g
1670185510.292048996
   RES
  3.1g
1670185510.444880393
   RES
  3.1g
1670185510.597966296
   RES
  3.1g
1670185510.751048264
   RES
  3.1g
1670185510.904017865
   RES
  3.1g
1670185511.056994959
   RES
  3.1g
1670185511.210118244
   RES
  3.1g
1670185511.363068604
   RES
  3.2g
1670185511.515782479
   RES
  3.2g
1670185511.668456544
   RES
  3.2g
1670185511.821445906
   RES
  3.3g
1670185511.974288895
   RES
  3.3g
1670185512.127183564
   RES
  3.4g
1670185512.280061431
   RES
  3.4g
1670185512.432741029
   RES
  3.4g
1670185512.585597785
   RES
  3.5g
1670185512.738500280
   RES
  3.5g
1670185512.891270483
   RES
  3.6g
1670185513.044094048
   RES
  3.6g
1670185513.196729362
   RES
  3.6g
1670185513.349575554
   RES
  3.6g
1670185513.502761988
   RES
  3.6g
1670185513.655828966
   RES
  3.6g
1670185513.808847465
   RES
  3.6g
1670185513.962153656
   RES
  3.6g
1670185514.115234463
   RES
  3.6g
1670185514.268275954
   RES
  3.6g
1670185514.421507848
   RES
  3.7g
1670185514.574314278
   RES
  3.7g
1670185514.727072488
   RES
  3.8g
1670185514.879807626
   RES
  3.8g
1670185515.032674056
   RES
  3.9g
1670185515.185598602
   RES
  3.9g
1670185515.338449087
   RES
  3.9g
1670185515.491267298
   RES
  4.0g
1670185515.644069445
   RES
  4.0g
1670185515.796833421
   RES
  4.1g
1670185515.949785670
   RES
  4.1g
1670185516.102880388
   RES
  4.2g
1670185516.255752781
   RES
  4.2g
1670185516.408596356
   RES
  4.2g
1670185516.561376606
   RES
  4.3g
1670185516.714215917
   RES
  4.0g
1670185516.867138596
   RES
  3.6g
1670185517.019985271
   RES
  3.5g
1670185517.172905547
   RES
  3.5g
1670185517.325944844
   RES
  3.5g
1670185517.478701764
   RES
  3.5g
1670185517.631380558
   RES
  3.5g
1670185517.784130947
   RES
  3.5g
1670185517.936960695
   RES
  3.3g
1670185518.089916918
   RES
  2.4g
1670185518.242863958
   RES
  2.4g
1670185518.395668440
   RES
  2.4g
1670185518.548468289
   RES
  2.4g
1670185518.701447864
   RES
  2.4g
1670185518.854303929
   RES
  2.4g
1670185519.007053210
   RES
  2.4g
1670185519.159934809
   RES
  2.4g
1670185519.312555239
   RES
  2.4g
1670185519.473051258
   RES
  2.4g
1670185519.625830095
   RES
  2.4g
1670185519.778640901
   RES
  2.4g
1670185519.931380874
   RES
  2.4g
1670185520.084115537
   RES
  2.4g
1670185520.237006485
   RES
  2.4g
1670185520.389926994
   RES
  2.4g
1670185520.542747891
   RES
  2.4g
1670185520.695560224
   RES
  2.4g
1670185520.848318771
   RES
  2.4g
1670185521.001152826
   RES
  2.4g
1670185521.154026528
   RES
  2.4g
1670185521.306835283
   RES
  2.4g
1670185521.459611591
   RES
  2.4g
1670185521.612255895
   RES
  2.4g
1670185521.765137847
   RES
  2.4g
1670185521.917930199
   RES
  2.4g
1670185522.070650060
   RES
  2.4g
1670185522.223332268
   RES
  2.4g
1670185522.376047362
   RES
  2.4g
1670185522.528925186
   RES
  2.4g
1670185522.681856725
   RES
  2.4g
1670185522.834694564
   RES
  2.4g
1670185522.987493907
   RES
  2.4g
1670185523.140169287
   RES
  2.4g
1670185523.292793093
   RES
  2.4g
1670185523.445652844
   RES
  2.4g
1670185523.598522281
   RES
  2.4g
1670185523.751364355
   RES
  2.4g
1670185523.904327081
   RES
  2.4g
1670185524.057226460
   RES
  2.4g
1670185524.210113711
   RES
  2.4g
1670185524.362959939
   RES
  2.4g
1670185524.523363288
   RES
  2.4g
1670185524.676103765
   RES
  2.4g
1670185524.828822533
   RES
  2.4g
1670185524.981651004
   RES
  2.4g
1670185525.134458220
   RES
  2.4g
1670185525.287269711
   RES
  2.4g
1670185525.440125265
   RES
  2.4g
1670185525.592839622
   RES
  2.4g
1670185525.745750782
   RES
  2.4g
1670185525.898599672
   RES
  2.4g
1670185526.051424372
   RES
  2.4g
1670185526.204276409
   RES
  2.4g
1670185526.357142634
   RES
  2.4g
1670185526.509957179
   RES
  2.4g
1670185526.662784582
   RES
  2.4g
1670185526.815511373
   RES
  2.4g
1670185526.968289367
   RES
  2.4g
1670185527.121133997
   RES
  2.4g
1670185527.273925391
   RES
  2.4g
1670185527.426663387
   RES
  2.4g
1670185527.579510860
   RES
  2.4g
1670185527.732315554
   RES
  2.4g
1670185527.885163865
   RES
  2.4g
1670185528.038086692
   RES
  2.4g
1670185528.190965619
   RES
  2.4g
1670185528.343824112
   RES
  2.4g
1670185528.496717664
   RES
  2.4g
1670185528.649617965
   RES
  2.4g
1670185528.802431327
   RES
  2.4g
1670185528.955250832
   RES
  2.4g
1670185529.108235393
   RES
  2.4g
1670185529.261071235
   RES
  2.4g
1670185529.413921623
   RES
  2.4g
1670185529.566657994
   RES
  2.4g
1670185529.719473867
   RES
  2.4g
1670185529.872452808
   RES
  2.4g
1670185530.025393258
   RES
  2.4g
1670185530.178209016
   RES
  2.4g
1670185530.331003377
   RES
  2.4g
1670185530.483764130
   RES
  2.4g
1670185530.636450102
   RES
  2.4g
1670185530.789308461
   RES
  2.4g
1670185530.942155971
   RES
  2.4g
1670185531.094954029
   RES
  2.4g
1670185531.247777386
   RES
  2.4g
1670185531.408205923
   RES
  2.4g
1670185531.560960286
   RES
  2.4g
1670185531.713803757
   RES
  2.4g
1670185531.866640891
   RES
  2.4g
1670185532.019480029
   RES
  2.4g
1670185532.172341848
   RES
  2.4g
1670185532.325240762
   RES
  2.4g
1670185532.478071788
   RES
  2.4g
1670185532.630811515
   RES
  2.4g
1670185532.783533337
   RES
  2.4g
1670185532.936340449
   RES
  2.4g
1670185533.089351035
   RES
  2.4g
1670185533.242212096
   RES
  2.4g
1670185533.395052675
   RES
  2.4g
1670185533.547938141
   RES
  2.4g
1670185533.700740714
   RES
  2.4g
1670185533.853614164
   RES
  2.4g
1670185534.006484262
   RES
  2.4g
1670185534.159262224
   RES
  2.4g
1670185534.312043640
   RES
  2.4g
1670185534.464733494
   RES
  2.4g
1670185534.617588223
   RES
  2.4g
1670185534.770400489
   RES
  2.4g
1670185534.923149346
   RES
  2.4g
1670185535.075935953
   RES
  2.4g
1670185535.228733395
   RES
  2.4g
1670185535.381551078
   RES
  2.4g
1670185535.534444193
   RES
  2.4g
1670185535.687256557
   RES
  2.4g
1670185535.840073185
   RES
  2.4g
1670185535.992780929
   RES
  2.4g
1670185536.145666929
   RES
  2.4g
1670185536.298512566
   RES
  2.4g
1670185536.458833468
   RES
  2.4g
1670185536.611676368
   RES
  2.4g
1670185536.764565283
   RES
  2.4g
1670185536.917560507
   RES
  2.4g
1670185537.070407976
   RES
  2.4g
1670185537.223215911
   RES
  2.4g
1670185537.375970100
   RES
  2.4g
1670185537.528836161
   RES
  2.4g
1670185537.681688137
   RES
  2.4g
1670185537.834449680
   RES
  2.4g
1670185537.987261776
   RES
  2.4g
1670185538.140042214
   RES
  2.4g
1670185538.292981750
   RES
  2.4g
1670185538.445833355
   RES
  2.4g
1670185538.598673329
   RES
  2.4g
1670185538.751407274
   RES
  2.4g
1670185538.904083382
   RES
  2.4g
1670185539.056783595
   RES
  2.4g
1670185539.209678445
   RES
  2.4g
1670185539.362439748
   RES
  2.4g
1670185539.515186335
   RES
  2.4g
1670185539.668074330
   RES
  2.4g
1670185539.820897209
   RES
  2.4g
1670185539.973822787
   RES
  2.4g
1670185540.126622475
   RES
  2.4g
1670185540.279431539
   RES
  2.4g
1670185540.432302581
   RES
  2.4g
1670185540.585176793
   RES
  2.4g
1670185540.738146631
   RES
  2.4g
1670185540.890951223
   RES
  2.4g
1670185541.043732910
   RES
  2.4g
1670185541.196438249
   RES
  2.4g
1670185541.349179930
   RES
  2.4g
1670185541.509600476
   RES
  2.4g
1670185541.662528539
   RES
  2.4g
1670185541.815308793
   RES
  2.4g
1670185541.968009701
   RES
  2.4g
1670185542.120759089
   RES
  2.4g
1670185542.273619464
   RES
  2.4g
1670185542.426460789
   RES
  2.4g
1670185542.579202833
   RES
  2.4g
1670185542.732051893
   RES
  2.4g
1670185542.884890703
   RES
  2.4g
1670185543.037795428
   RES
  2.4g
1670185543.190512595
   RES
  2.4g
1670185543.343349294
   RES
  2.4g
1670185543.496199259
   RES
  2.4g
1670185543.648887446
   RES
  2.4g
1670185543.801770325
   RES
  2.4g
1670185543.954683550
   RES
  2.4g
1670185544.107490853
   RES
  2.4g
1670185544.260171897
   RES
  2.4g
1670185544.412993417
   RES
  2.4g
1670185544.565826741
   RES
  2.4g
1670185544.718568258
   RES
  2.4g
1670185544.871401937
   RES
  2.4g
1670185545.024323438
   RES
  2.4g
1670185545.177250462
   RES
  2.4g
1670185545.330058926
   RES
  2.4g
1670185545.482813283
   RES
  2.4g
1670185545.635595032
   RES
  2.4g
1670185545.788382508
   RES
  2.4g
1670185545.941427950
   RES
  2.4g
1670185546.094260268
   RES
  2.4g
1670185546.247073941
   RES
  2.4g
1670185546.400363587
   RES
  2.2g
1670185546.554098555
   RES
  2.2g
1670185546.707867849
   RES
  2.2g
1670185546.860795119
   RES
  2.2g
1670185547.013841895
   RES
  2.2g
1670185547.167007949
   RES
  2.2g
1670185547.319984186
   RES
  2.2g
1670185547.472918711
   RES
  2.2g
1670185547.626120520
   RES
  2.2g
1670185547.779182428
   RES
  2.1g
1670185547.932174597
   RES
698948
1670185548.085086711
   RES
1670185548.240971500
1670185548.244640206
   RES
 90240
1670185548.404851761
   RES
138600
1670185548.558943208
   RES
201732
1670185548.713412697
   RES
217280
1670185548.867648196
   RES
237752
1670185549.022048397
   RES
260740
1670185549.176337158
   RES
277180
1670185549.330654774
   RES
281048
1670185549.485241369
   RES
284772
1670185549.641654986
   RES
286504
1670185549.800673014
   RES
294132
1670185549.957975641
   RES
307128
1670185550.117268796
   RES
328176
1670185550.274449499
   RES
334228
1670185550.432102625
   RES
334228
1670185550.591820085
   RES
362468
1670185550.747213949
   RES
419324
1670185550.904945792
   RES
454324
1670185551.067832156
   RES
436948
1670185551.242642333
   RES
447624
1670185551.417349173
   RES
491716
1670185551.584137523
   RES
500476
1670185551.753868688
   RES
501264
1670185551.914549595
   RES
501032
1670185552.078582142
   RES
500508
1670185552.243242694
   RES
499232
1670185552.406853812
   RES
492104
1670185552.570170486
   RES
492104
1670185552.732377883
   RES
492632
1670185552.890872805
   RES
492596
1670185553.051273766
   RES
476128
1670185553.223122843
   RES
494412
1670185553.395966907
   RES
478348
1670185553.561477248
   RES
478348
1670185553.722907363
   RES
477832
1670185553.888604586
   RES
477832
1670185554.069943876
   RES
477456
1670185554.248472581
   RES
478248
1670185554.414014438
   RES
478220
1670185554.576589950
   RES
477704
1670185554.738058139
   RES
502516
1670185554.905346950
   RES
510628
1670185555.068504582
   RES
510628
1670185555.234593734
   RES
510628
1670185555.397636090
   RES
511420
1670185555.559403820
   RES
511384
1670185555.722325320
   RES
510868
1670185555.886105866
   RES
519048
1670185556.055398446
   RES
527232
1670185556.222044550
   RES
528024
1670185556.384799526
   RES
527976
1670185556.549402522
   RES
527460
1670185556.712093261
   RES
527460
1670185556.875440708
   RES
469540
1670185557.036324906
   RES
478248
1670185557.200303569
   RES
478220
1670185557.363891604
   RES
477704
1670185557.532704519
   RES
477704
1670185557.696721980
   RES
471648
1670185557.862087110
   RES
477456
1670185558.024538206
   RES
477456
1670185558.186889654
   RES
469540
1670185558.357540180
   RES
477456
1670185558.521846801
   RES
510456
1670185558.683737710
   RES
494044
1670185558.847781622
   RES
502380
1670185559.013933581
   RES
519012
1670185559.177632138
   RES
511004
1670185559.340693278
   RES
524464
1670185559.504501964
   RES
535552
1670185559.668144417
   RES
535552
1670185559.836430777
   RES
508256
1670185560.006274447
   RES
502192
1670185560.183216624
   RES
502192
1670185560.350316405
   RES
502192
1670185560.511802118
   RES
502192
1670185560.674253658
   RES
502192
1670185560.840916502
   RES
504620
1670185561.007748543
   RES
498360
1670185561.174783888
   RES
498360
1670185561.340316333
   RES
498360
1670185561.503907064
   RES
498360
1670185561.666376749
   RES
498360
1670185561.829714177
   RES
488716
1670185561.995393786
   RES
488716
1670185562.160974857
   RES
488716
1670185562.322666468
   RES
488716
1670185562.487527563
   RES
488716
1670185562.651218287
   RES
505080
1670185562.814348439
   RES
505080
1670185562.976250306
   RES
505080
1670185563.138977159
   RES
488716
1670185563.299898316
   RES
488716
1670185563.463268752
   RES
488716
1670185563.627617159
   RES
496632
1670185563.794354741
   RES
480424
1670185563.958774232
   RES
480424
1670185564.124646775
   RES
480400
1670185564.289247050
   RES
480400
1670185564.450592267
   RES
480400
1670185564.613371007
   RES
479560
1670185564.777275450
   RES
479560
1670185564.942563340
   RES
504108
1670185565.103918812
   RES
469540
1670185565.264892535
   RES
485904
1670185565.425951027
   RES
494044
1670185565.588417225
   RES
494044
1670185565.750181386
   RES
502492
1670185565.916863043
   RES
502492
1670185566.082330905
   RES
502492
1670185566.245701150
   RES
494044
1670185566.405160142
   RES
494044
1670185566.566178338
   RES
502492
1670185566.729347314
   RES
494420
1670185566.890506684
   RES
513424
1670185567.049666115
   RES
518968
1670185567.210962479
   RES
518968
1670185567.374320584
   RES
518968
1670185567.539209333
   RES
519760
1670185567.699518690
   RES
519688
1670185567.860377059
   RES
519172
1670185568.022971548
   RES
535536
1670185568.185919632
   RES
535536
1670185568.351488389
   RES
535536
1670185568.516015829
   RES
510632
1670185568.678651009
   RES
510632
1670185568.841979731
   RES
472136
1670185569.003955153
   RES
480428
1670185569.164282301
   RES
480428
1670185569.325670488
   RES
477460
1670185569.485844414
   RES
477460
1670185569.650680340
   RES
485908
1670185569.812655163
   RES
477836
1670185569.974020317
   RES
477460
1670185570.135102179
   RES
486132
1670185570.297459600
   RES
486132
1670185570.458836691
   RES
485908
1670185570.622873159
   RES
477460
1670185570.786384977
   RES
477460
1670185570.947246054
   RES
469544
1670185571.109418408
   RES
477460
1670185571.269886406
   RES
474028
1670185571.427963195
   RES
477460
1670185571.588611169
   RES
485908
1670185571.750094606
   RES
494048
1670185571.909185844
   RES
494048
1670185572.072611666
   RES
485752
1670185572.235032807
   RES
469544
1670185572.398271733
   RES
477460
1670185572.564283910
   RES
477836
1670185572.726346354
   RES
477836
1670185572.884921911
   RES
477460
1670185573.045236313
   RES
477460
1670185573.207412736
   RES
486132
1670185573.368961462
   RES
469544
1670185573.529463297
   RES
502540
1670185573.689564684
   RES
494048
1670185573.849786387
   RES
494048
1670185574.010830586
   RES
477836
1670185574.169733630
   RES
477836
1670185574.330716872
   RES
486132
1670185574.495476471
   RES
494048
1670185574.656250052
   RES
485908
1670185574.815621344
   RES
477724
1670185574.977396230
   RES
478300
1670185575.138875528
   RES
477784
1670185575.298570158
   RES
477784
1670185575.460329196
   RES
483716
1670185575.622251837
   RES
478328
1670185575.780726634
   RES
478044
1670185575.939505544
   RES
478304
1670185576.099946902
   RES
477716
1670185576.263518926
   RES
477716
1670185576.424666522
   RES
477468
1670185576.585208184
   RES
478260
1670185576.751461339
   RES
478236
1670185576.915396757
   RES
477976
1670185577.077079605
   RES
477976
1670185577.242515843
   RES
478104
1670185577.405900734
   RES
486176
1670185577.566108671
   RES
511276
1670185577.727279871
   RES
494316
1670185577.892732625
   RES
486020
1670185578.054277689
   RES
486020
1670185578.215542790
   RES
486176
1670185578.376238782
   RES
494316
1670185578.536358101
   RES
494316
1670185578.700342353
   RES
510948
1670185578.868916704
   RES
517140
1670185579.029480512
   RES
527532
1670185579.189171549
   RES
535980
1670185579.352379884
   RES
535980
1670185579.517715467
   RES
544164
1670185579.679952356
   RES
544164
1670185579.841117054
   RES
544164
1670185580.003212160
   RES
527860
1670185580.165361561
   RES
527860
1670185580.328735777
   RES
535776
1670185580.493427684
   RES
535776
1670185580.653506175
   RES
535776
1670185580.812355179
   RES
478104
1670185580.972442822
   RES
469812
1670185581.141166926
   RES
499640
1670185581.308278698
   RES
502608
1670185581.471585821
   RES
502608
1670185581.631485562
   RES
519240
1670185581.793164936
   RES
519240
1670185581.953202807
   RES
519568
1670185582.117302115
   RES
502608
1670185582.279380628
   RES
516072
1670185582.439452637
   RES
519240
1670185582.598002720
   RES
494692
1670185582.765354251
   RES
502608
1670185582.926057925
   RES
502608
1670185583.087087864
   RES
519240
1670185583.248551447
   RES
519240
1670185583.407595301
=================
Namespace(gnn='GCN', k=10, i=4, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only=True, compression_rate='big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 2068
In epoch 0, student train loss: 3.362, student train acc: 0.007, student val loss: 3.358, student val acc: 0.004 (best student val acc: 0.004))
In epoch 20, student train loss: 1.780, student train acc: 0.633, student val loss: 1.252, student val acc: 0.737 (best student val acc: 0.737))
In epoch 40, student train loss: 1.622, student train acc: 0.633, student val loss: 1.257, student val acc: 0.737 (best student val acc: 0.737))
In epoch 60, student train loss: 1.481, student train acc: 0.644, student val loss: 1.132, student val acc: 0.737 (best student val acc: 0.737))
In epoch 80, student train loss: 1.326, student train acc: 0.654, student val loss: 1.011, student val acc: 0.739 (best student val acc: 0.739))
   RES
527860
1670185583.565930148
   RES
527860
1670185583.725452424
   RES
544224
1670185583.886382711
   RES
544224
1670185584.044072136
   RES
527860
1670185584.205137676
   RES
535776
1670185584.364989326
   RES
486020
1670185584.525907880
   RES
486812
1670185584.686901305
   RES
486608
1670185584.844883195
   RES
469892
1670185585.003499679
   RES
486244
1670185585.162755664
   RES
494924
1670185585.320725899
   RES
494900
1670185585.479217818
   RES
494900
1670185585.637138687
   RES
494900
1670185585.793550625
   RES
494568
1670185585.952158829
   RES
527564
1670185586.110871783
   RES
528092
1670185586.268259391
   RES
528000
1670185586.425253280
=================
Namespace(gnn='GCN', k=10, i=5, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only=True, compression_rate='big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 2068
In epoch 0, student train loss: 3.396, student train acc: 0.005, student val loss: 3.391, student val acc: 0.001 (best student val acc: 0.001))
In epoch 20, student train loss: 1.575, student train acc: 0.630, student val loss: 1.248, student val acc: 0.661 (best student val acc: 0.662))
In epoch 40, student train loss: 1.449, student train acc: 0.630, student val loss: 1.237, student val acc: 0.661 (best student val acc: 0.662))
In epoch 60, student train loss: 1.384, student train acc: 0.632, student val loss: 1.184, student val acc: 0.661 (best student val acc: 0.662))
In epoch 80, student train loss: 1.314, student train acc: 0.642, student val loss: 1.137, student val acc: 0.666 (best student val acc: 0.666))
   RES
527744
1670185586.582820814
   RES
519408
1670185586.739825743
   RES
494856
1670185586.896763449
   RES
494576
1670185587.055129460
   RES
494576
1670185587.213486318
   RES
494336
1670185587.370149792
=================
Namespace(gnn='GCN', k=10, i=6, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only=True, compression_rate='big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 2068
In epoch 0, student train loss: 3.431, student train acc: 0.001, student val loss: 3.420, student val acc: 0.001 (best student val acc: 0.001))
In epoch 20, student train loss: 1.035, student train acc: 0.719, student val loss: 1.201, student val acc: 0.622 (best student val acc: 0.631))
In epoch 40, student train loss: 0.895, student train acc: 0.730, student val loss: 1.033, student val acc: 0.639 (best student val acc: 0.639))
In epoch 60, student train loss: 0.800, student train acc: 0.771, student val loss: 0.952, student val acc: 0.706 (best student val acc: 0.706))
In epoch 80, student train loss: 0.759, student train acc: 0.781, student val loss: 0.905, student val acc: 0.721 (best student val acc: 0.721))
   RES
494312
1670185587.527569016
   RES
494312
1670185587.683853274
   RES
493788
1670185587.839880625
   RES
510148
1670185587.997529554
   RES
510916
1670185588.154468284
   RES
510896
1670185588.309519376
   RES
494180
1670185588.464918847
   RES
494436
1670185588.620869649
   RES
494180
1670185588.776211129
   RES
480704
1670185588.933037000
=================
Namespace(gnn='GCN', k=10, i=3, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only=True, compression_rate='big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 2068
In epoch 0, student train loss: 3.345, student train acc: 0.009, student val loss: 3.337, student val acc: 0.006 (best student val acc: 0.006))
In epoch 20, student train loss: 2.715, student train acc: 0.208, student val loss: 2.494, student val acc: 0.339 (best student val acc: 0.345))
In epoch 40, student train loss: 2.451, student train acc: 0.275, student val loss: 2.228, student val acc: 0.367 (best student val acc: 0.368))
In epoch 60, student train loss: 2.179, student train acc: 0.327, student val loss: 2.017, student val acc: 0.392 (best student val acc: 0.392))
In epoch 80, student train loss: 1.951, student train acc: 0.395, student val loss: 1.845, student val acc: 0.421 (best student val acc: 0.421))
   RES
490468
1670185589.089706517
   RES
504868
1670185589.245589837
   RES
504868
1670185589.400631814
   RES
504836
1670185589.556173492
   RES
521120
1670185589.711354564
   RES
529832
1670185589.866626367
   RES
513008
1670185590.021957970
   RES
503352
1670185590.178997124
=================
Namespace(gnn='GCN', k=10, i=7, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only=True, compression_rate='big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 2068
In epoch 0, student train loss: 3.352, student train acc: 0.023, student val loss: 3.340, student val acc: 0.023 (best student val acc: 0.023))
In epoch 20, student train loss: 1.984, student train acc: 0.495, student val loss: 2.281, student val acc: 0.321 (best student val acc: 0.322))
In epoch 40, student train loss: 1.725, student train acc: 0.512, student val loss: 1.977, student val acc: 0.369 (best student val acc: 0.369))
In epoch 60, student train loss: 1.485, student train acc: 0.584, student val loss: 1.712, student val acc: 0.498 (best student val acc: 0.498))
In epoch 80, student train loss: 1.345, student train acc: 0.636, student val loss: 1.580, student val acc: 0.523 (best student val acc: 0.523))
   RES
503352
1670185590.334331498
   RES
503608
1670185590.489388552
   RES
503352
1670185590.643869390
   RES
491588
1670185590.798696657
=================
Namespace(gnn='GCN', k=10, i=8, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only=True, compression_rate='big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 2068
In epoch 0, student train loss: 3.340, student train acc: 0.008, student val loss: 3.347, student val acc: 0.003 (best student val acc: 0.003))
In epoch 20, student train loss: 2.369, student train acc: 0.365, student val loss: 2.440, student val acc: 0.271 (best student val acc: 0.271))
In epoch 40, student train loss: 2.202, student train acc: 0.313, student val loss: 2.267, student val acc: 0.239 (best student val acc: 0.277))
In epoch 60, student train loss: 2.033, student train acc: 0.424, student val loss: 2.018, student val acc: 0.348 (best student val acc: 0.348))
In epoch 80, student train loss: 1.860, student train acc: 0.475, student val loss: 1.778, student val acc: 0.424 (best student val acc: 0.424))
   RES
505312
1670185590.953493983
   RES
505708
1670185591.107745885
   RES
469820
1670185591.261222819
   RES
494852
1670185591.415869781
   RES
494576
1670185591.570762265
   RES
477740
1670185591.725799140
=================
Namespace(gnn='GCN', k=10, i=2, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only=True, compression_rate='big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 2068
In epoch 0, student train loss: 3.322, student train acc: 0.011, student val loss: 3.321, student val acc: 0.004 (best student val acc: 0.004))
In epoch 20, student train loss: 1.761, student train acc: 0.572, student val loss: 1.446, student val acc: 0.634 (best student val acc: 0.634))
In epoch 40, student train loss: 1.643, student train acc: 0.572, student val loss: 1.419, student val acc: 0.634 (best student val acc: 0.634))
In epoch 60, student train loss: 1.586, student train acc: 0.572, student val loss: 1.383, student val acc: 0.634 (best student val acc: 0.634))
In epoch 80, student train loss: 1.523, student train acc: 0.572, student val loss: 1.353, student val acc: 0.634 (best student val acc: 0.634))
   RES
494856
1670185591.879939162
   RES
511112
1670185592.034250323
   RES
528008
1670185592.188097822
   RES
535920
1670185592.342250164
   RES
536036
1670185592.496736904
   RES
494856
1670185592.650946331
   RES
488936
1670185592.804961797
   RES
494824
1670185592.959492939
   RES
486556
1670185593.112903027
   RES
494328
1670185593.266456268
   RES
486668
1670185593.420273465
   RES
494324
1670185593.574010825
   RES
494480
1670185593.727654704
   RES
494576
1670185593.881500223
   RES
486540
1670185594.035207964
   RES
469820
1670185594.188763719
   RES
503252
1670185594.342905644
   RES
511432
1670185594.496731219
=================
Namespace(gnn='GCN', k=10, i=10, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only=True, compression_rate='big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 2068
In epoch 0, student train loss: 3.311, student train acc: 0.009, student val loss: 3.302, student val acc: 0.010 (best student val acc: 0.010))
In epoch 20, student train loss: 2.557, student train acc: 0.144, student val loss: 2.501, student val acc: 0.122 (best student val acc: 0.262))
In epoch 40, student train loss: 2.467, student train acc: 0.179, student val loss: 2.433, student val acc: 0.262 (best student val acc: 0.282))
In epoch 60, student train loss: 2.359, student train acc: 0.207, student val loss: 2.355, student val acc: 0.272 (best student val acc: 0.306))
In epoch 80, student train loss: 2.191, student train acc: 0.329, student val loss: 2.213, student val acc: 0.339 (best student val acc: 0.339))
   RES
461540
1670185594.651090760
   RES
     0
1670185594.804619613
   RES
1670185594.957914601
   RES
1670185595.111003040
   RES
1670185595.264286591
   RES
1670185595.417464421
   RES
1670185595.570966713
   RES
1670185595.724211859
   RES
1670185595.877600275
   RES
1670185596.030966987
   RES
1670185596.184224165
   RES
1670185596.337232166
   RES
1670185596.490364511
   RES
1670185596.643437826
   RES
1670185596.797006576
   RES
1670185596.950823814
   RES
1670185597.104447017
   RES
1670185597.257771088
   RES
1670185597.411013612
   RES
1670185597.564157805
   RES
1670185597.717798622
   RES
1670185597.871057604
   RES
1670185598.024580952
   RES
1670185598.178128061
   RES
1670185598.331622922
   RES
1670185598.484933824
   RES
1670185598.638272065
   RES
1670185598.791690727
   RES
1670185598.944835328
   RES
1670185599.098485442
   RES
1670185599.251608272
   RES
1670185599.404929586
   RES
1670185599.557995357
   RES
1670185599.711289658
   RES
1670185599.864150844
=================
Namespace(gnn='GCN', k=10, i=1, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only=True, compression_rate='big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 2068
In epoch 0, student train loss: 3.320, student train acc: 0.008, student val loss: 3.325, student val acc: 0.006 (best student val acc: 0.006))
In epoch 20, student train loss: 2.638, student train acc: 0.210, student val loss: 2.466, student val acc: 0.263 (best student val acc: 0.329))
In epoch 40, student train loss: 2.355, student train acc: 0.265, student val loss: 2.186, student val acc: 0.348 (best student val acc: 0.348))
In epoch 60, student train loss: 2.065, student train acc: 0.362, student val loss: 1.917, student val acc: 0.421 (best student val acc: 0.421))
In epoch 80, student train loss: 1.829, student train acc: 0.420, student val loss: 1.713, student val acc: 0.475 (best student val acc: 0.475))
   RES
1670185600.017248175
   RES
1670185600.170354215
   RES
1670185600.323844430
   RES
1670185600.476687296
=================
Namespace(gnn='GCN', k=10, i=9, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only=True, compression_rate='big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 2068
In epoch 0, student train loss: 3.318, student train acc: 0.009, student val loss: 3.323, student val acc: 0.002 (best student val acc: 0.002))
In epoch 20, student train loss: 2.229, student train acc: 0.359, student val loss: 2.156, student val acc: 0.402 (best student val acc: 0.403))
In epoch 40, student train loss: 1.948, student train acc: 0.395, student val loss: 1.893, student val acc: 0.444 (best student val acc: 0.444))
In epoch 60, student train loss: 1.761, student train acc: 0.466, student val loss: 1.724, student val acc: 0.511 (best student val acc: 0.511))
In epoch 80, student train loss: 1.619, student train acc: 0.516, student val loss: 1.589, student val acc: 0.544 (best student val acc: 0.544))
   RES
1670185600.629711486
   RES
1670185600.786091025
1670185600.791032075
1670185600.793486165
