1670191232.748844641
   RES
119916
1670191232.904820759
   RES
208132
1670191233.057603885
   RES
244952
1670191233.210400747
   RES
291392
1670191233.363223336
   RES
322272
1670191233.516310092
   RES
674684
1670191233.669596657
   RES
767532
1670191233.823036020
   RES
796308
1670191233.976033611
   RES
820068
1670191234.128947807
   RES
849636
1670191234.281851891
   RES
882896
1670191234.434799051
   RES
897416
1670191234.587852979
   RES
937804
1670191234.740731274
   RES
959452
1670191234.893692942
   RES
987964
1670191235.046744808
   RES
  1.0g
1670191235.199952462
   RES
  1.0g
1670191235.352782067
   RES
  1.0g
1670191235.505602835
   RES
  1.1g
1670191235.658461995
   RES
  1.1g
1670191235.811298559
   RES
  1.1g
1670191235.964156201
   RES
  1.1g
1670191236.116954076
   RES
  1.2g
1670191236.269662796
   RES
  1.2g
1670191236.422552118
   RES
  1.2g
1670191236.575778087
   RES
  1.2g
1670191236.728559746
   RES
  1.3g
1670191236.881536777
   RES
  1.3g
1670191237.034428687
   RES
  1.4g
1670191237.187222547
   RES
  1.4g
1670191237.340231005
   RES
  1.4g
1670191237.493127489
   RES
  1.4g
1670191237.646061525
   RES
  1.5g
1670191237.798936050
   RES
  1.5g
1670191237.951874716
   RES
  1.6g
1670191238.104669733
   RES
  1.6g
1670191238.257767782
   RES
  1.6g
1670191238.410699351
   RES
  1.6g
1670191238.563642691
   RES
  1.7g
1670191238.716444026
   RES
  1.7g
1670191238.869456057
   RES
  1.8g
1670191239.022414782
   RES
  1.8g
1670191239.175320492
   RES
  1.9g
1670191239.328175019
   RES
  1.9g
1670191239.481169387
   RES
  1.9g
1670191239.634257609
   RES
  1.9g
1670191239.787296588
   RES
  1.9g
1670191239.940147694
   RES
  1.9g
1670191240.093044496
   RES
  2.0g
1670191240.245934589
   RES
  2.0g
1670191240.398785416
   RES
  2.1g
1670191240.551627185
   RES
  2.1g
1670191240.704386694
   RES
  2.1g
1670191240.857189070
   RES
  2.2g
1670191241.010166223
   RES
  2.2g
1670191241.163036184
   RES
  2.3g
1670191241.315856321
   RES
  2.3g
1670191241.468586790
   RES
  2.3g
1670191241.621892038
   RES
  2.3g
1670191241.774941078
   RES
  2.3g
1670191241.928052327
   RES
  2.3g
1670191242.081092385
   RES
  2.4g
1670191242.233906507
   RES
  2.4g
1670191242.386635441
   RES
  2.5g
1670191242.539375078
   RES
  2.5g
1670191242.692315717
   RES
  2.5g
1670191242.845582723
   RES
  2.5g
1670191242.998742797
   RES
  2.5g
1670191243.151834205
   RES
  2.5g
1670191243.304954782
   RES
  2.5g
1670191243.457995954
   RES
  2.6g
1670191243.610877962
   RES
  2.7g
1670191243.763515251
   RES
  2.7g
1670191243.916312981
   RES
  2.8g
1670191244.069141426
   RES
  2.8g
1670191244.222129821
   RES
  2.8g
1670191244.375163265
   RES
  2.8g
1670191244.528241480
   RES
  2.8g
1670191244.681305803
   RES
  2.8g
1670191244.834320197
   RES
  2.8g
1670191244.987261876
   RES
  2.9g
1670191245.140126057
   RES
  2.9g
1670191245.293038216
   RES
  3.0g
1670191245.453678609
   RES
  3.0g
1670191245.606693377
   RES
  3.0g
1670191245.759764598
   RES
  3.0g
1670191245.913075020
   RES
  3.0g
1670191246.066245670
   RES
  3.0g
1670191246.219287519
   RES
  3.0g
1670191246.372234677
   RES
  3.1g
1670191246.525062565
   RES
  3.1g
1670191246.677974019
   RES
  3.1g
1670191246.831024016
   RES
  3.1g
1670191246.984144656
   RES
  3.1g
1670191247.137335832
   RES
  3.1g
1670191247.290432645
   RES
  3.1g
1670191247.443530788
   RES
  3.1g
1670191247.596448841
   RES
  3.2g
1670191247.749477577
   RES
  3.2g
1670191247.902279098
   RES
  3.2g
1670191248.055169719
   RES
  3.3g
1670191248.208024387
   RES
  3.3g
1670191248.360953133
   RES
  3.4g
1670191248.513934783
   RES
  3.4g
1670191248.666864576
   RES
  3.4g
1670191248.819680619
   RES
  3.5g
1670191248.972509448
   RES
  3.5g
1670191249.125577326
   RES
  3.6g
1670191249.278407106
   RES
  3.6g
1670191249.431304733
   RES
  3.6g
1670191249.584493701
   RES
  3.6g
1670191249.737661239
   RES
  3.6g
1670191249.890799734
   RES
  3.6g
1670191250.043916859
   RES
  3.6g
1670191250.197076941
   RES
  3.6g
1670191250.350129179
   RES
  3.6g
1670191250.503201235
   RES
  3.6g
1670191250.656149134
   RES
  3.7g
1670191250.809064908
   RES
  3.7g
1670191250.961980971
   RES
  3.8g
1670191251.114943128
   RES
  3.8g
1670191251.267725355
   RES
  3.9g
1670191251.420498023
   RES
  3.9g
1670191251.573480930
   RES
  3.9g
1670191251.726283668
   RES
  4.0g
1670191251.879198251
   RES
  4.0g
1670191252.032116426
   RES
  4.1g
1670191252.184931316
   RES
  4.1g
1670191252.337843347
   RES
  4.2g
1670191252.490694372
   RES
  4.2g
1670191252.643590677
   RES
  4.3g
1670191252.796525296
   RES
  4.3g
1670191252.949479644
   RES
  3.9g
1670191253.102366960
   RES
  3.6g
1670191253.255377149
   RES
  3.5g
1670191253.408058496
   RES
  3.5g
1670191253.560711131
   RES
  3.5g
1670191253.713631540
   RES
  3.5g
1670191253.866507883
   RES
  3.5g
1670191254.019374612
   RES
  3.5g
1670191254.172362429
   RES
  3.1g
1670191254.325352524
   RES
  2.4g
1670191254.478270948
   RES
  2.4g
1670191254.631077210
   RES
  2.4g
1670191254.783971965
   RES
  2.4g
1670191254.936671386
   RES
  2.4g
1670191255.089581541
   RES
  2.4g
1670191255.242433351
   RES
  2.4g
1670191255.395286273
   RES
  2.4g
1670191255.548133090
   RES
  2.4g
1670191255.700929165
   RES
  2.4g
1670191255.853867926
   RES
  2.4g
1670191256.006870924
   RES
  2.4g
1670191256.159832447
   RES
  2.4g
1670191256.312611231
   RES
  2.4g
1670191256.465580855
   RES
  2.4g
1670191256.618350487
   RES
  2.4g
1670191256.771167024
   RES
  2.4g
1670191256.923982290
   RES
  2.4g
1670191257.076763624
   RES
  2.4g
1670191257.229533410
   RES
  2.4g
1670191257.382314916
   RES
  2.4g
1670191257.535228968
   RES
  2.4g
1670191257.688068553
   RES
  2.4g
1670191257.840877880
   RES
  2.4g
1670191257.993845134
   RES
  2.4g
1670191258.146836275
   RES
  2.4g
1670191258.299721434
   RES
  2.4g
1670191258.452756109
   RES
  2.4g
1670191258.613162960
   RES
  2.4g
1670191258.766175688
   RES
  2.4g
1670191258.919019385
   RES
  2.4g
1670191259.071883389
   RES
  2.4g
1670191259.224785404
   RES
  2.4g
1670191259.377613728
   RES
  2.4g
1670191259.530396933
   RES
  2.4g
1670191259.683240357
   RES
  2.4g
1670191259.836071720
   RES
  2.4g
1670191259.988780907
   RES
  2.4g
1670191260.141795395
   RES
  2.4g
1670191260.294683864
   RES
  2.4g
1670191260.447703927
   RES
  2.4g
1670191260.600491178
   RES
  2.4g
1670191260.753369168
   RES
  2.4g
1670191260.906247371
   RES
  2.4g
1670191261.059184972
   RES
  2.4g
1670191261.212068986
   RES
  2.4g
1670191261.364785919
   RES
  2.4g
1670191261.517719105
   RES
  2.4g
1670191261.670621471
   RES
  2.4g
1670191261.823495427
   RES
  2.4g
1670191261.976288495
   RES
  2.4g
1670191262.129252656
   RES
  2.4g
1670191262.282313493
   RES
  2.4g
1670191262.435137229
   RES
  2.4g
1670191262.587963049
   RES
  2.4g
1670191262.740886376
   RES
  2.4g
1670191262.893755627
   RES
  2.4g
1670191263.046782723
   RES
  2.4g
1670191263.199814100
   RES
  2.4g
1670191263.352718605
   RES
  2.4g
1670191263.505763622
   RES
  2.4g
1670191263.658579018
   RES
  2.4g
1670191263.811400461
   RES
  2.4g
1670191263.964237639
   RES
  2.4g
1670191264.117146116
   RES
  2.4g
1670191264.270031599
   RES
  2.4g
1670191264.422922505
   RES
  2.4g
1670191264.575776237
   RES
  2.4g
1670191264.728550943
   RES
  2.4g
1670191264.881588256
   RES
  2.4g
1670191265.034445474
   RES
  2.4g
1670191265.187297958
   RES
  2.4g
1670191265.340235313
   RES
  2.4g
1670191265.493157913
   RES
  2.4g
1670191265.646154674
   RES
  2.4g
1670191265.806492912
   RES
  2.4g
1670191265.959331540
   RES
  2.4g
1670191266.112298513
   RES
  2.4g
1670191266.265123238
   RES
  2.4g
1670191266.417985910
   RES
  2.4g
1670191266.570886394
   RES
  2.4g
1670191266.723774455
   RES
  2.4g
1670191266.876694324
   RES
  2.4g
1670191267.029682935
   RES
  2.4g
1670191267.182502488
   RES
  2.4g
1670191267.335351106
   RES
  2.4g
1670191267.488152572
   RES
  2.4g
1670191267.640909552
   RES
  2.4g
1670191267.793876131
   RES
  2.4g
1670191267.946720751
   RES
  2.4g
1670191268.099562743
   RES
  2.4g
1670191268.252395954
   RES
  2.4g
1670191268.405242785
   RES
  2.4g
1670191268.558061682
   RES
  2.4g
1670191268.710978659
   RES
  2.4g
1670191268.863797535
   RES
  2.4g
1670191269.016783280
   RES
  2.4g
1670191269.169667233
   RES
  2.4g
1670191269.322610464
   RES
  2.4g
1670191269.475636946
   RES
  2.4g
1670191269.628426811
   RES
  2.4g
1670191269.781227591
   RES
  2.4g
1670191269.934132025
   RES
  2.4g
1670191270.086994640
   RES
  2.4g
1670191270.240071567
   RES
  2.4g
1670191270.392952960
   RES
  2.4g
1670191270.545868096
   RES
  2.4g
1670191270.698643196
   RES
  2.4g
1670191270.851535441
   RES
  2.4g
1670191271.004358666
   RES
  2.4g
1670191271.157312999
   RES
  2.4g
1670191271.310150004
   RES
  2.4g
1670191271.462881062
   RES
  2.4g
1670191271.615818055
   RES
  2.4g
1670191271.768611848
   RES
  2.4g
1670191271.921533215
   RES
  2.4g
1670191272.074328303
   RES
  2.4g
1670191272.227190821
   RES
  2.4g
1670191272.379835407
   RES
  2.4g
1670191272.532700789
   RES
  2.4g
1670191272.685711498
   RES
  2.4g
1670191272.838757907
   RES
  2.4g
1670191272.991478318
   RES
  2.4g
1670191273.144315468
   RES
  2.4g
1670191273.297143343
   RES
  2.4g
1670191273.450136573
   RES
  2.4g
1670191273.602870740
   RES
  2.4g
1670191273.755672858
   RES
  2.4g
1670191273.908501027
   RES
  2.4g
1670191274.061319223
   RES
  2.4g
1670191274.214243743
   RES
  2.4g
1670191274.367108072
   RES
  2.4g
1670191274.519926753
   RES
  2.4g
1670191274.672666541
   RES
  2.4g
1670191274.825565510
   RES
  2.4g
1670191274.978402086
   RES
  2.4g
1670191275.131197933
   RES
  2.4g
1670191275.284097447
   RES
  2.4g
1670191275.436957044
   RES
  2.4g
1670191275.589769417
   RES
  2.4g
1670191275.742610965
   RES
  2.4g
1670191275.895485652
   RES
  2.4g
1670191276.048235834
   RES
  2.4g
1670191276.201050986
   RES
  2.4g
1670191276.353852768
   RES
  2.4g
1670191276.506775505
   RES
  2.4g
1670191276.659657525
   RES
  2.4g
1670191276.812370371
   RES
  2.4g
1670191276.965248224
   RES
  2.4g
1670191277.118104286
   RES
  2.4g
1670191277.271006683
   RES
  2.4g
1670191277.424014413
   RES
  2.4g
1670191277.576745378
   RES
  2.4g
1670191277.729733086
   RES
  2.4g
1670191277.882565594
   RES
  2.4g
1670191278.035423576
   RES
  2.4g
1670191278.188226027
   RES
  2.4g
1670191278.340994146
   RES
  2.4g
1670191278.493718740
   RES
  2.4g
1670191278.646590994
   RES
  2.4g
1670191278.799363186
   RES
  2.4g
1670191278.952354190
   RES
  2.4g
1670191279.105181287
   RES
  2.4g
1670191279.257923757
   RES
  2.4g
1670191279.410682365
   RES
  2.4g
1670191279.563412670
   RES
  2.4g
1670191279.716214266
   RES
  2.4g
1670191279.869211405
   RES
  2.4g
1670191280.022525390
   RES
  2.4g
1670191280.175502408
   RES
  2.4g
1670191280.328481068
   RES
  2.4g
1670191280.481460175
   RES
  2.4g
1670191280.634456970
   RES
  2.4g
1670191280.787268012
   RES
  2.4g
1670191280.940154075
   RES
  2.4g
1670191281.092891429
   RES
  2.4g
1670191281.245699338
   RES
  2.4g
1670191281.398476740
   RES
  2.4g
1670191281.551281986
   RES
  2.4g
1670191281.704246173
   RES
  2.4g
1670191281.857256226
   RES
  2.4g
1670191282.010176566
   RES
  2.4g
1670191282.162880443
   RES
  2.4g
1670191282.315557991
   RES
  2.4g
1670191282.468555083
   RES
  2.4g
1670191282.621660282
   RES
  2.4g
1670191282.774623695
   RES
  2.4g
1670191282.927431350
   RES
  2.4g
1670191283.080338779
   RES
  2.4g
1670191283.233273149
   RES
  2.2g
1670191283.388288822
   RES
  2.2g
1670191283.541538340
   RES
  2.2g
1670191283.694709943
   RES
  2.2g
1670191283.847719908
   RES
  2.2g
1670191284.000879554
   RES
  2.2g
1670191284.154132533
   RES
  2.2g
1670191284.307138888
   RES
  2.2g
1670191284.460160787
   RES
  2.2g
1670191284.613138087
   RES
  2.2g
1670191284.766202352
   RES
699360
1670191284.919263115
   RES
1670191285.075416348
1670191285.079022120
   RES
 87284
1670191285.236172787
   RES
133600
1670191285.390491851
   RES
200776
1670191285.545153813
   RES
216000
1670191285.699786671
   RES
235500
1670191285.854505828
   RES
259792
1670191286.008826988
   RES
276432
1670191286.163217756
   RES
279980
1670191286.318577262
   RES
284300
1670191286.476283027
   RES
286028
1670191286.636412727
   RES
286404
1670191286.794593982
   RES
303896
1670191286.954198993
   RES
315736
1670191287.112266195
   RES
329628
1670191287.273742430
   RES
333220
1670191287.433584342
   RES
333220
1670191287.606439887
   RES
343328
1670191287.767430367
   RES
418256
1670191287.925493208
   RES
428584
1670191288.086875917
   RES
429800
1670191288.248132422
   RES
467392
1670191288.408339606
   RES
497904
1670191288.569903105
   RES
498444
1670191288.731679883
   RES
498444
1670191288.891610858
   RES
498444
1670191289.052290022
   RES
498444
1670191289.214762146
   RES
498704
1670191289.376031144
   RES
498700
1670191289.538249302
   RES
498444
1670191289.701891956
   RES
498444
1670191289.867639408
   RES
514828
1670191290.027732312
   RES
548092
1670191290.192550865
   RES
548620
1670191290.357585031
   RES
548452
1670191290.518286853
   RES
548196
1670191290.680523123
   RES
548196
1670191290.844605079
   RES
498568
1670191291.005919750
   RES
467472
1670191291.167762572
   RES
507332
1670191291.331118474
   RES
492608
1670191291.493734437
   RES
492612
1670191291.653215207
   RES
500272
1670191291.814343456
   RES
492356
1670191291.987007233
   RES
491464
1670191292.149589150
   RES
491620
1670191292.310215054
   RES
483548
1670191292.474265637
   RES
500176
1670191292.637372894
   RES
483548
1670191292.798518330
   RES
483808
1670191292.955379156
   RES
483800
1670191293.116540353
   RES
483544
1670191293.276313541
   RES
524460
1670191293.439797576
   RES
524724
1670191293.601355177
   RES
524728
1670191293.761922954
   RES
524472
1670191293.922216656
   RES
489756
1670191294.081874320
   RES
490016
1670191294.253761326
   RES
489760
1670191294.420792598
   RES
522756
1670191294.584846627
   RES
522756
1670191294.745861795
   RES
523284
1670191294.908146796
   RES
523052
1670191295.068183593
   RES
522796
1670191295.233914452
   RES
506008
1670191295.395810626
   RES
489904
1670191295.562100727
   RES
486368
1670191295.721254056
   RES
523064
1670191295.880912731
   RES
523052
1670191296.039302155
   RES
523052
1670191296.198498243
   RES
522796
1670191296.357514876
   RES
530888
1670191296.518315712
   RES
514892
1670191296.685285397
   RES
514636
1670191296.847802846
   RES
505968
1670191297.008322250
   RES
506468
1670191297.170119783
   RES
506212
1670191297.329077714
   RES
514632
1670191297.489504621
   RES
514892
1670191297.648538190
   RES
514892
1670191297.808694518
   RES
514892
1670191297.970749975
   RES
531000
1670191298.130276823
   RES
531528
1670191298.292275682
   RES
531344
1670191298.456214982
   RES
531344
1670191298.617465104
   RES
531344
1670191298.779253286
   RES
531344
1670191298.939074377
   RES
510652
1670191299.099030125
   RES
504008
1670191299.264044754
   RES
504004
1670191299.422944110
   RES
504004
1670191299.584289236
   RES
528344
1670191299.742000220
   RES
536528
1670191299.899703792
   RES
509192
1670191300.060130064
   RES
509188
1670191300.218908551
   RES
508932
1670191300.381185729
   RES
492488
1670191300.540121012
   RES
476540
1670191300.700901266
   RES
484200
1670191300.859954228
   RES
517464
1670191301.018483895
   RES
517872
1670191301.178964039
   RES
517872
1670191301.337316429
   RES
517616
1670191301.497838947
   RES
525796
1670191301.663821217
   RES
526324
1670191301.823535495
   RES
525920
1670191301.982517157
   RES
480956
1670191302.142830310
   RES
489400
1670191302.303756826
   RES
489116
1670191302.463945049
   RES
519472
1670191302.623931643
   RES
478620
1670191302.785027155
   RES
478620
1670191302.942738463
   RES
478360
1670191303.101882241
   RES
478360
1670191303.261027379
   RES
486804
1670191303.422172132
   RES
486776
1670191303.582279908
   RES
486776
1670191303.743644486
   RES
485688
1670191303.909506250
   RES
485688
1670191304.068629441
   RES
485692
1670191304.230633651
   RES
462484
1670191304.394243853
   RES
462484
1670191304.553629148
   RES
462472
1670191304.714307100
   RES
462472
1670191304.873539058
   RES
478572
1670191305.033166427
   RES
454436
1670191305.193530507
   RES
454436
1670191305.355385931
   RES
478728
1670191305.517117097
   RES
487544
1670191305.679185394
   RES
487536
1670191305.840984146
   RES
495196
1670191306.004655474
   RES
503644
1670191306.167063631
   RES
511828
1670191306.326328456
   RES
475436
1670191306.484657399
   RES
475436
1670191306.645526019
   RES
475964
1670191306.805782496
   RES
475692
1670191306.964076486
   RES
484116
1670191307.124115034
   RES
484376
1670191307.285019879
   RES
484368
1670191307.448767507
   RES
503524
1670191307.608879922
   RES
504052
1670191307.768006510
   RES
503936
1670191307.928412451
   RES
520044
1670191308.088007100
   RES
528688
1670191308.246788856
   RES
528948
1670191308.404263585
   RES
528936
1670191308.565279865
   RES
528680
1670191308.728560105
   RES
528680
1670191308.891886501
   RES
511200
1670191309.053642966
   RES
511200
1670191309.214442418
   RES
511200
1670191309.375406709
   RES
511728
1670191309.536053140
   RES
511708
1670191309.698543585
   RES
511452
1670191309.862009187
   RES
498196
1670191310.022226052
   RES
506644
1670191310.182811141
   RES
515356
1670191310.344156719
   RES
515292
1670191310.505017156
   RES
498576
1670191310.661922111
   RES
506492
1670191310.820538220
   RES
507020
1670191310.980030587
   RES
506996
1670191311.139243694
   RES
481096
1670191311.299976512
   RES
476440
1670191311.458087732
   RES
476160
1670191311.618060262
   RES
505724
1670191311.778403631
   RES
481092
1670191311.939626850
   RES
445224
1670191312.099533512
   RES
509456
1670191312.258157580
   RES
484840
1670191312.416201565
   RES
484840
1670191312.575818290
   RES
484584
1670191312.735531268
   RES
525764
1670191312.894886665
   RES
534464
1670191313.054197408
   RES
534464
1670191313.212674737
   RES
534464
1670191313.374180981
   RES
542908
1670191313.534689891
   RES
542760
1670191313.693563144
   RES
504016
1670191313.854365617
   RES
504016
1670191314.027222935
   RES
504012
1670191314.188409286
   RES
504012
1670191314.347616614
   RES
503752
1670191314.506690811
   RES
504012
1670191314.666443896
   RES
504012
1670191314.826695029
   RES
504012
1670191314.985666924
   RES
504012
1670191315.147591191
   RES
512192
1670191315.312341734
   RES
512192
1670191315.476610860
   RES
519824
1670191315.637422517
   RES
503488
1670191315.797739858
   RES
511668
1670191315.974247513
   RES
511660
1670191316.133812928
   RES
511660
1670191316.296989155
   RES
511660
1670191316.458282120
   RES
511404
1670191316.620537124
   RES
520112
1670191316.780652083
   RES
519956
1670191316.940867754
   RES
503240
1670191317.102900424
   RES
518020
1670191317.265968229
   RES
503240
1670191317.429167006
   RES
511156
1670191317.594157530
   RES
511664
1670191317.754385700
   RES
511408
1670191317.913680748
   RES
511408
1670191318.078916361
   RES
520116
1670191318.243004233
   RES
519952
1670191318.406661094
   RES
519952
1670191318.568595195
   RES
503236
1670191318.729754336
   RES
511152
1670191318.894745775
   RES
520128
1670191319.061574714
   RES
519956
1670191319.224305153
   RES
503496
1670191319.386499101
   RES
511676
1670191319.549629592
   RES
511676
1670191319.712899389
   RES
511660
1670191319.874946298
   RES
519840
1670191320.036860112
   RES
519856
1670191320.197515438
   RES
503492
1670191320.360868798
   RES
514576
1670191320.523862971
   RES
520080
1670191320.686242053
   RES
520084
1670191320.847138078
   RES
520084
1670191321.011232956
   RES
520084
1670191321.172169156
   RES
519828
1670191321.334884686
   RES
501724
1670191321.522994638
   RES
501724
1670191321.687694692
   RES
501980
1670191321.850461579
   RES
501980
1670191322.011436059
   RES
509368
1670191322.173622306
   RES
509632
1670191322.337650397
   RES
509632
1670191322.499158537
   RES
509584
1670191322.661708488
   RES
509584
1670191322.823248504
   RES
509584
1670191322.984841266
   RES
509584
1670191323.146160248
   RES
509588
1670191323.307091621
   RES
509588
1670191323.466619232
   RES
509588
1670191323.627514450
   RES
509588
1670191323.788557108
   RES
509584
1670191323.951029571
   RES
517764
1670191324.114067663
   RES
501420
1670191324.274272468
   RES
501420
1670191324.438986094
   RES
501420
1670191324.606106523
   RES
518004
1670191324.767283951
   RES
501420
1670191324.928524575
   RES
501420
1670191325.090289866
   RES
501428
1670191325.252342692
   RES
501428
1670191325.413553781
   RES
501428
1670191325.578010946
   RES
501428
1670191325.739518060
   RES
501428
1670191325.897743094
   RES
501428
1670191326.057172566
   RES
501420
1670191326.219489035
   RES
509336
1670191326.379443657
   RES
509588
1670191326.538773143
   RES
509588
1670191326.699618258
   RES
509588
1670191326.863260512
   RES
509588
1670191327.024276097
   RES
509584
1670191327.184360898
   RES
498452
1670191327.346893285
   RES
498452
1670191327.507593051
   RES
498716
1670191327.667643257
   RES
498704
1670191327.829639185
   RES
498444
1670191327.992981909
   RES
507152
1670191328.153039038
   RES
506988
1670191328.315109449
   RES
498192
1670191328.476514268
   RES
506860
1670191328.639275993
   RES
507120
1670191328.800715399
   RES
475908
1670191328.964944843
   RES
476288
1670191329.126663137
   RES
476288
1670191329.284741724
   RES
476548
1670191329.447336200
   RES
476540
1670191329.609054584
   RES
476284
1670191329.768190409
   RES
476024
1670191329.928865520
   RES
476024
1670191330.091986214
   RES
475768
1670191330.256285290
   RES
514640
1670191330.418286049
   RES
490024
1670191330.581694297
   RES
490016
1670191330.743518917
   RES
490016
1670191330.902399650
   RES
489760
1670191331.065555765
   RES
530940
1670191331.226832449
   RES
531468
1670191331.390564856
   RES
531352
1670191331.554702862
   RES
531352
1670191331.719313733
   RES
531352
1670191331.878028366
   RES
531352
1670191332.039530102
   RES
531348
1670191332.202615458
   RES
531348
1670191332.363710743
   RES
531352
1670191332.529041872
   RES
531352
1670191332.691517280
   RES
531352
1670191332.851309190
   RES
490508
1670191333.010314758
   RES
474144
1670191333.173527936
   RES
474144
1670191333.336364857
   RES
474144
1670191333.496789033
   RES
485756
1670191333.661833146
   RES
482576
1670191333.827338543
   RES
482324
1670191333.985415976
   RES
501592
1670191334.144400870
   RES
482452
1670191334.304219728
   RES
482168
1670191334.467328875
   RES
482128
1670191334.630235911
   RES
490200
1670191334.797121374
   RES
473708
1670191334.960084465
   RES
506764
1670191335.123200947
   RES
481888
1670191335.284492754
   RES
481888
1670191335.447066643
   RES
481888
1670191335.611106434
   RES
481624
1670191335.777956536
   RES
522804
1670191335.941904558
   RES
522804
1670191336.101067708
   RES
498468
1670191336.260683162
   RES
498456
1670191336.425537180
   RES
498456
1670191336.590510058
   RES
493256
1670191336.766768052
   RES
518016
1670191336.939833988
   RES
543276
1670191337.119370107
   RES
526844
1670191337.282211386
   RES
526616
1670191337.441728234
   RES
526360
1670191337.606702429
   RES
534808
1670191337.769222064
   RES
543228
1670191337.931325632
   RES
543496
1670191338.095091508
   RES
543496
1670191338.258987388
   RES
543496
1670191338.421001783
   RES
543240
1670191338.581902947
   RES
543240
1670191338.747654736
   RES
553532
1670191338.910405783
   RES
551920
1670191339.073009792
   RES
551912
1670191339.233728810
   RES
551912
1670191339.393229256
   RES
568276
1670191339.555532548
   RES
568276
1670191339.718659722
   RES
568540
1670191339.881169049
   RES
568540
1670191340.042406135
   RES
568372
1670191340.204903396
   RES
568372
1670191340.368476038
   RES
576552
1670191340.530720667
   RES
576816
1670191340.691798519
   RES
576816
1670191340.853283297
   RES
576816
1670191341.014176218
   RES
576668
1670191341.174792618
   RES
576668
1670191341.335400782
   RES
555920
1670191341.496471985
   RES
573080
1670191341.659142257
   RES
581000
1670191341.819759938
   RES
581000
1670191341.980312060
   RES
580812
1670191342.142911013
   RES
564356
1670191342.304978242
   RES
546216
1670191342.469039398
   RES
546216
1670191342.632761800
   RES
546216
1670191342.794902027
   RES
529632
1670191342.956978112
   RES
529632
1670191343.122887920
   RES
529632
1670191343.284980729
   RES
529632
1670191343.445981528
   RES
529632
1670191343.611589103
   RES
523712
1670191343.773327298
   RES
529256
1670191343.935312830
   RES
537704
1670191344.094948981
   RES
545840
1670191344.256321048
   RES
545840
1670191344.418501902
   RES
562472
1670191344.580177081
   RES
570920
1670191344.746497483
   RES
570920
1670191344.910397319
   RES
570920
1670191345.072848347
   RES
571184
1670191345.237232236
   RES
570964
1670191345.399539563
   RES
570964
1670191345.565521232
   RES
579144
1670191345.730554467
   RES
587328
1670191345.891430337
   RES
587328
1670191346.054364195
   RES
533776
1670191346.219247242
   RES
533776
1670191346.383406072
   RES
533776
1670191346.545473235
   RES
533772
1670191346.708273629
   RES
533772
1670191346.868868590
   RES
553568
1670191347.029316113
   RES
561616
1670191347.189600992
   RES
573784
1670191347.351587770
   RES
578248
1670191347.517676334
   RES
586872
1670191347.679755350
   RES
587132
1670191347.839996468
   RES
587132
1670191348.003881912
   RES
586884
1670191348.170284369
   RES
586884
1670191348.333337217
   RES
561628
1670191348.494357500
   RES
561892
1670191348.659209846
   RES
561892
1670191348.821135757
   RES
561892
1670191348.980134831
   RES
561880
1670191349.142088875
   RES
561620
1670191349.305334542
   RES
561620
1670191349.470044110
   RES
541484
1670191349.632212462
   RES
541744
1670191349.793524424
   RES
541740
1670191349.957675031
   RES
541484
1670191350.123266560
   RES
541484
1670191350.287721353
   RES
549136
1670191350.449257815
   RES
549400
1670191350.610731570
   RES
549400
1670191350.774700213
   RES
558068
1670191350.938535186
   RES
558068
1670191351.100039251
   RES
559384
1670191351.264091760
   RES
574432
1670191351.427872601
   RES
574432
1670191351.590360236
   RES
574432
1670191351.757053867
   RES
574432
1670191351.923795349
   RES
582616
1670191352.087100474
   RES
582616
1670191352.254262832
   RES
582616
1670191352.416674995
   RES
582616
1670191352.578755151
   RES
582616
1670191352.744931128
   RES
583084
1670191352.904159076
   RES
582828
1670191353.065992090
   RES
582828
1670191353.226222079
   RES
582828
1670191353.388337061
   RES
582828
1670191353.549934969
   RES
582828
1670191353.711123093
   RES
583088
1670191353.873927332
   RES
583072
1670191354.034013158
   RES
582816
1670191354.195758806
   RES
582816
1670191354.361286539
   RES
582816
1670191354.522320042
   RES
583076
1670191354.681642809
   RES
583072
1670191354.843682356
   RES
582816
1670191355.007075004
   RES
582816
1670191355.169706856
   RES
583076
1670191355.330043902
   RES
583072
1670191355.490978093
   RES
583072
1670191355.652609882
   RES
583072
1670191355.814884525
   RES
582812
1670191355.976600842
   RES
582812
1670191356.141536347
   RES
571364
1670191356.305251005
   RES
574796
1670191356.468264952
   RES
574772
1670191356.630062880
   RES
574516
1670191356.791454329
   RES
574516
1670191356.955018120
   RES
549248
1670191357.117028225
   RES
557164
1670191357.280202627
   RES
557672
1670191357.443111063
   RES
557416
1670191357.605022706
   RES
557416
1670191357.767721664
   RES
565836
1670191357.927084343
   RES
553536
1670191358.088432654
   RES
561984
1670191358.251968242
   RES
570168
1670191358.415516679
   RES
570636
1670191358.579079042
   RES
570636
1670191358.740997753
   RES
570636
1670191358.904303723
   RES
570380
1670191359.068548578
   RES
570380
1670191359.231730438
   RES
560284
1670191359.392764229
   RES
560812
1670191359.554449729
   RES
560788
1670191359.714561302
   RES
560788
1670191359.874379925
   RES
560788
1670191360.036422194
   RES
551756
1670191360.197466768
   RES
551756
1670191360.361279135
   RES
551756
1670191360.522037169
   RES
558088
1670191360.684164402
   RES
591352
1670191360.849238828
   RES
591352
1670191361.013972236
=================
Namespace(gnn='GCN', k=10, i=6, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only='n', compression_rate='Big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 10856
In epoch 0, train loss: 3.757, train acc: 0.036, val loss: 3.726, val acc: 0.040 (best val acc: 0.040))
In epoch 20, train loss: 0.946, train acc: 0.772, val loss: 1.100, val acc: 0.710 (best val acc: 0.710))
In epoch 40, train loss: 0.796, train acc: 0.788, val loss: 0.963, val acc: 0.727 (best val acc: 0.728))
In epoch 60, train loss: 0.713, train acc: 0.797, val loss: 0.884, val acc: 0.739 (best val acc: 0.739))
In epoch 80, train loss: 0.659, train acc: 0.805, val loss: 0.833, val acc: 0.747 (best val acc: 0.747))
In epoch 0, student train loss: 3.394, student train acc: 0.001, student val loss: 3.385, student val acc: 0.000 (best student val acc: 0.000))
In epoch 20, student train loss: 0.957, student train acc: 0.721, student val loss: 1.101, student val acc: 0.625 (best student val acc: 0.625))
In epoch 40, student train loss: 0.785, student train acc: 0.776, student val loss: 0.939, student val acc: 0.715 (best student val acc: 0.715))
In epoch 60, student train loss: 0.710, student train acc: 0.787, student val loss: 0.861, student val acc: 0.729 (best student val acc: 0.729))
In epoch 80, student train loss: 0.649, student train acc: 0.794, student val loss: 0.801, student val acc: 0.736 (best student val acc: 0.738))
   RES
591616
1670191361.175712379
   RES
591368
1670191361.334751655
=================
Namespace(gnn='GCN', k=10, i=4, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only='n', compression_rate='Big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 10856
In epoch 0, train loss: 3.755, train acc: 0.002, val loss: 3.763, val acc: 0.000 (best val acc: 0.000))
In epoch 20, train loss: 1.612, train acc: 0.649, val loss: 1.239, val acc: 0.738 (best val acc: 0.738))
In epoch 40, train loss: 1.221, train acc: 0.707, val loss: 0.948, val acc: 0.779 (best val acc: 0.779))
In epoch 60, train loss: 1.029, train acc: 0.737, val loss: 0.833, val acc: 0.793 (best val acc: 0.793))
In epoch 80, train loss: 0.928, train acc: 0.756, val loss: 0.789, val acc: 0.796 (best val acc: 0.796))
In epoch 0, student train loss: 3.208, student train acc: 0.021, student val loss: 3.200, student val acc: 0.007 (best student val acc: 0.007))
In epoch 20, student train loss: 1.541, student train acc: 0.633, student val loss: 1.198, student val acc: 0.737 (best student val acc: 0.737))
In epoch 40, student train loss: 1.220, student train acc: 0.679, student val loss: 0.922, student val acc: 0.764 (best student val acc: 0.764))
In epoch 60, student train loss: 1.030, student train acc: 0.716, student val loss: 0.798, student val acc: 0.787 (best student val acc: 0.787))
In epoch 80, student train loss: 0.919, student train acc: 0.738, student val loss: 0.748, student val acc: 0.793 (best student val acc: 0.793))
   RES
591368
1670191361.494914091
   RES
591360
1670191361.656325739
   RES
574900
1670191361.815325225
   RES
574900
1670191361.973742847
   RES
574900
1670191362.134701528
   RES
582816
1670191362.292909759
   RES
582816
1670191362.450906581
   RES
583068
1670191362.608379532
   RES
583068
1670191362.765060937
   RES
566608
1670191362.922998088
   RES
566608
1670191363.079387708
   RES
566608
1670191363.234815610
   RES
566608
1670191363.390919168
   RES
566612
1670191363.548238604
   RES
550028
1670191363.706796094
   RES
550028
1670191363.865590542
   RES
550028
1670191364.021226932
   RES
550028
1670191364.178620519
   RES
560320
1670191364.335732350
   RES
549388
1670191364.491997074
   RES
549372
1670191364.648006062
   RES
590816
1670191364.805030754
   RES
590816
1670191364.961322150
   RES
590836
1670191365.117886262
   RES
590836
1670191365.274480676
   RES
590836
1670191365.430675330
=================
Namespace(gnn='GCN', k=10, i=8, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only='n', compression_rate='Big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 10856
In epoch 0, train loss: 3.704, train acc: 0.007, val loss: 3.727, val acc: 0.001 (best val acc: 0.001))
In epoch 20, train loss: 2.075, train acc: 0.455, val loss: 2.004, val acc: 0.428 (best val acc: 0.438))
In epoch 40, train loss: 1.677, train acc: 0.525, val loss: 1.595, val acc: 0.561 (best val acc: 0.561))
In epoch 60, train loss: 1.455, train acc: 0.570, val loss: 1.408, val acc: 0.576 (best val acc: 0.585))
In epoch 80, train loss: 1.315, train acc: 0.608, val loss: 1.317, val acc: 0.598 (best val acc: 0.599))
In epoch 0, student train loss: 3.311, student train acc: 0.019, student val loss: 3.290, student val acc: 0.064 (best student val acc: 0.064))
In epoch 20, student train loss: 1.947, student train acc: 0.441, student val loss: 1.862, student val acc: 0.414 (best student val acc: 0.414))
In epoch 40, student train loss: 1.619, student train acc: 0.497, student val loss: 1.488, student val acc: 0.513 (best student val acc: 0.514))
In epoch 60, student train loss: 1.418, student train acc: 0.541, student val loss: 1.330, student val acc: 0.547 (best student val acc: 0.547))
In epoch 80, student train loss: 1.287, student train acc: 0.577, student val loss: 1.240, student val acc: 0.567 (best student val acc: 0.567))
   RES
590836
1670191365.588431797
=================
Namespace(gnn='GCN', k=10, i=7, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only='n', compression_rate='Big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 10856
In epoch 0, train loss: 3.735, train acc: 0.005, val loss: 3.738, val acc: 0.003 (best val acc: 0.003))
In epoch 20, train loss: 1.670, train acc: 0.583, val loss: 1.975, val acc: 0.446 (best val acc: 0.446))
In epoch 40, train loss: 1.314, train acc: 0.693, val loss: 1.585, val acc: 0.588 (best val acc: 0.588))
In epoch 60, train loss: 1.127, train acc: 0.717, val loss: 1.382, val acc: 0.634 (best val acc: 0.634))
In epoch 80, train loss: 1.015, train acc: 0.733, val loss: 1.255, val acc: 0.671 (best val acc: 0.671))
In epoch 0, student train loss: 3.341, student train acc: 0.017, student val loss: 3.320, student val acc: 0.024 (best student val acc: 0.024))
In epoch 20, student train loss: 1.696, student train acc: 0.530, student val loss: 1.977, student val acc: 0.360 (best student val acc: 0.360))
In epoch 40, student train loss: 1.400, student train acc: 0.655, student val loss: 1.654, student val acc: 0.536 (best student val acc: 0.539))
In epoch 60, student train loss: 1.220, student train acc: 0.685, student val loss: 1.452, student val acc: 0.587 (best student val acc: 0.587))
In epoch 80, student train loss: 1.092, student train acc: 0.708, student val loss: 1.315, student val acc: 0.615 (best student val acc: 0.616))
   RES
574380
1670191365.745781464
   RES
574380
1670191365.901770923
   RES
556068
1670191366.058223829
=================
Namespace(gnn='GCN', k=10, i=3, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only='n', compression_rate='Big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 10856
In epoch 0, train loss: 3.660, train acc: 0.036, val loss: 3.653, val acc: 0.030 (best val acc: 0.030))
In epoch 20, train loss: 2.336, train acc: 0.407, val loss: 2.223, val acc: 0.437 (best val acc: 0.437))
In epoch 40, train loss: 1.682, train acc: 0.531, val loss: 1.726, val acc: 0.498 (best val acc: 0.498))
In epoch 60, train loss: 1.440, train acc: 0.589, val loss: 1.550, val acc: 0.537 (best val acc: 0.537))
In epoch 80, train loss: 1.327, train acc: 0.613, val loss: 1.487, val acc: 0.548 (best val acc: 0.548))
In epoch 0, student train loss: 3.296, student train acc: 0.030, student val loss: 3.305, student val acc: 0.011 (best student val acc: 0.011))
In epoch 20, student train loss: 2.330, student train acc: 0.320, student val loss: 2.190, student val acc: 0.400 (best student val acc: 0.400))
In epoch 40, student train loss: 1.697, student train acc: 0.487, student val loss: 1.692, student val acc: 0.480 (best student val acc: 0.480))
In epoch 60, student train loss: 1.419, student train acc: 0.554, student val loss: 1.474, student val acc: 0.524 (best student val acc: 0.524))
In epoch 80, student train loss: 1.294, student train acc: 0.586, student val loss: 1.389, student val acc: 0.533 (best student val acc: 0.533))
   RES
556068
1670191366.214614746
   RES
556068
1670191366.370259248
   RES
556068
1670191366.525313588
   RES
556068
1670191366.681078627
   RES
556068
1670191366.836144505
   RES
555812
1670191366.997098076
=================
Namespace(gnn='GCN', k=10, i=5, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only='n', compression_rate='Big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 10856
In epoch 0, train loss: 3.743, train acc: 0.002, val loss: 3.731, val acc: 0.003 (best val acc: 0.003))
In epoch 20, train loss: 1.528, train acc: 0.638, val loss: 1.301, val acc: 0.665 (best val acc: 0.665))
In epoch 40, train loss: 1.224, train acc: 0.703, val loss: 1.107, val acc: 0.709 (best val acc: 0.709))
In epoch 60, train loss: 1.064, train acc: 0.732, val loss: 0.980, val acc: 0.740 (best val acc: 0.740))
In epoch 80, train loss: 0.977, train acc: 0.750, val loss: 0.915, val acc: 0.754 (best val acc: 0.754))
In epoch 0, student train loss: 3.387, student train acc: 0.005, student val loss: 3.375, student val acc: 0.005 (best student val acc: 0.005))
In epoch 20, student train loss: 1.458, student train acc: 0.630, student val loss: 1.251, student val acc: 0.661 (best student val acc: 0.664))
In epoch 40, student train loss: 1.271, student train acc: 0.648, student val loss: 1.103, student val acc: 0.669 (best student val acc: 0.669))
In epoch 60, student train loss: 1.104, student train acc: 0.697, student val loss: 0.996, student val acc: 0.702 (best student val acc: 0.702))
In epoch 80, student train loss: 0.995, student train acc: 0.720, student val loss: 0.918, student val acc: 0.721 (best student val acc: 0.721))
   RES
543632
1670191367.152175719
   RES
543376
1670191367.307120040
   RES
525236
1670191367.462312471
   RES
542084
1670191367.616602644
   RES
549740
1670191367.770664666
   RES
558188
1670191367.925712392
   RES
558540
1670191368.079772205
   RES
528520
1670191368.234057405
   RES
528772
1670191368.388310208
   RES
536432
1670191368.542146468
   RES
536936
1670191368.695890877
   RES
536432
1670191368.850183812
   RES
536960
1670191369.004494973
   RES
527452
1670191369.159314480
   RES
536380
1670191369.313648620
   RES
519536
1670191369.467640429
   RES
535744
1670191369.622148346
   RES
585640
1670191369.776490397
   RES
559444
1670191369.930791273
   RES
558200
1670191370.085095080
   RES
575360
1670191370.239139298
   RES
558588
1670191370.393015425
   RES
575176
1670191370.547510015
   RES
575420
1670191370.700767836
   RES
558576
1670191370.854555253
   RES
558832
1670191371.009025511
   RES
558576
1670191371.162850166
   RES
558832
1670191371.317200211
   RES
558572
1670191371.471168764
   RES
564112
1670191371.625397941
   RES
545692
1670191371.779547596
   RES
532916
1670191371.933317767
   RES
532916
1670191372.087838982
   RES
534960
1670191372.242870905
   RES
576408
1670191372.397109624
   RES
576684
1670191372.551219435
   RES
576684
1670191372.705070742
   RES
560484
1670191372.859796672
   RES
525628
1670191373.014278743
   RES
525956
1670191373.168988907
   RES
525444
1670191373.323828906
   RES
558704
1670191373.477941863
   RES
558544
1670191373.631601293
   RES
566716
1670191373.785982179
   RES
566980
1670191373.940366846
   RES
566828
1670191374.094095584
   RES
575272
1670191374.248170671
   RES
575120
1670191374.402419293
   RES
575120
1670191374.557748629
   RES
540836
1670191374.713525759
   RES
557468
1670191374.869138670
   RES
501276
1670191375.023370615
   RES
501652
1670191375.177785787
   RES
543376
1670191375.331468491
   RES
543376
1670191375.485213958
   RES
559508
1670191375.639620071
   RES
559580
1670191375.793630971
   RES
557696
1670191375.947735030
   RES
526020
1670191376.102018088
   RES
542432
1670191376.256163263
   RES
568736
1670191376.410620406
   RES
591968
1670191376.565550916
   RES
527980
1670191376.720539023
   RES
527968
1670191376.874521374
   RES
536148
1670191377.028755311
   RES
544596
1670191377.182697526
   RES
544552
1670191377.336361609
   RES
526840
1670191377.490726491
   RES
551716
1670191377.645156973
   RES
551808
1670191377.799743960
   RES
534836
1670191377.953559583
   RES
543016
1670191378.107523057
   RES
543016
1670191378.261544616
   RES
534828
1670191378.416156016
   RES
542744
1670191378.570974386
   RES
542996
1670191378.724781424
   RES
543124
1670191378.878968983
   RES
543124
1670191379.033551682
   RES
543124
1670191379.188062263
   RES
525124
1670191379.341474683
   RES
525376
1670191379.495668419
   RES
551244
1670191379.650169998
   RES
541976
1670191379.804328288
   RES
526820
1670191379.958488603
   RES
541224
1670191380.112594178
   RES
541224
1670191380.266997310
   RES
531204
1670191380.420605519
   RES
529276
1670191380.574560910
   RES
512688
1670191380.728426266
   RES
520116
1670191380.882058798
   RES
520380
1670191381.036106934
   RES
495612
1670191381.190101355
   RES
545252
1670191381.344427138
   RES
545240
1670191381.498201720
   RES
545368
1670191381.652733534
   RES
535348
1670191381.806912908
=================
Namespace(gnn='GCN', k=10, i=9, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only='n', compression_rate='Big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 10856
In epoch 0, train loss: 3.707, train acc: 0.027, val loss: 3.715, val acc: 0.014 (best val acc: 0.014))
In epoch 20, train loss: 1.975, train acc: 0.484, val loss: 1.941, val acc: 0.520 (best val acc: 0.520))
In epoch 40, train loss: 1.598, train acc: 0.576, val loss: 1.588, val acc: 0.584 (best val acc: 0.584))
In epoch 60, train loss: 1.415, train acc: 0.601, val loss: 1.430, val acc: 0.601 (best val acc: 0.603))
In epoch 80, train loss: 1.301, train acc: 0.622, val loss: 1.334, val acc: 0.612 (best val acc: 0.612))
In epoch 0, student train loss: 3.316, student train acc: 0.004, student val loss: 3.308, student val acc: 0.001 (best student val acc: 0.001))
In epoch 20, student train loss: 1.936, student train acc: 0.402, student val loss: 1.885, student val acc: 0.446 (best student val acc: 0.448))
In epoch 40, student train loss: 1.565, student train acc: 0.542, student val loss: 1.540, student val acc: 0.556 (best student val acc: 0.556))
In epoch 60, student train loss: 1.394, student train acc: 0.580, student val loss: 1.380, student val acc: 0.586 (best student val acc: 0.587))
In epoch 80, student train loss: 1.289, student train acc: 0.597, student val loss: 1.294, student val acc: 0.600 (best student val acc: 0.600))
   RES
535348
1670191381.960422750
=================
Namespace(gnn='GCN', k=10, i=1, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only='n', compression_rate='Big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 10856
In epoch 0, train loss: 3.711, train acc: 0.008, val loss: 3.713, val acc: 0.001 (best val acc: 0.001))
In epoch 20, train loss: 2.372, train acc: 0.360, val loss: 2.252, val acc: 0.418 (best val acc: 0.422))
In epoch 40, train loss: 1.804, train acc: 0.494, val loss: 1.719, val acc: 0.526 (best val acc: 0.526))
In epoch 60, train loss: 1.571, train acc: 0.551, val loss: 1.521, val acc: 0.555 (best val acc: 0.555))
In epoch 80, train loss: 1.452, train acc: 0.582, val loss: 1.450, val acc: 0.571 (best val acc: 0.571))
In epoch 0, student train loss: 3.348, student train acc: 0.037, student val loss: 3.376, student val acc: 0.019 (best student val acc: 0.019))
In epoch 20, student train loss: 2.367, student train acc: 0.299, student val loss: 2.191, student val acc: 0.373 (best student val acc: 0.388))
In epoch 40, student train loss: 1.827, student train acc: 0.440, student val loss: 1.706, student val acc: 0.484 (best student val acc: 0.484))
In epoch 60, student train loss: 1.536, student train acc: 0.513, student val loss: 1.458, student val acc: 0.528 (best student val acc: 0.528))
In epoch 80, student train loss: 1.402, student train acc: 0.553, student val loss: 1.356, student val acc: 0.551 (best student val acc: 0.551))
   RES
576528
1670191382.115012586
   RES
560224
1670191382.268881765
   RES
543636
1670191382.422605663
   RES
535344
1670191382.576374798
=================
Namespace(gnn='GCN', k=10, i=2, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only='n', compression_rate='Big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 10856
In epoch 0, train loss: 3.624, train acc: 0.042, val loss: 3.617, val acc: 0.050 (best val acc: 0.050))
In epoch 20, train loss: 1.733, train acc: 0.573, val loss: 1.524, val acc: 0.634 (best val acc: 0.634))
In epoch 40, train loss: 1.410, train acc: 0.620, val loss: 1.311, val acc: 0.656 (best val acc: 0.656))
In epoch 60, train loss: 1.201, train acc: 0.677, val loss: 1.147, val acc: 0.692 (best val acc: 0.693))
In epoch 80, train loss: 1.092, train acc: 0.697, val loss: 1.063, val acc: 0.706 (best val acc: 0.706))
In epoch 0, student train loss: 3.234, student train acc: 0.013, student val loss: 3.221, student val acc: 0.000 (best student val acc: 0.000))
In epoch 20, student train loss: 1.637, student train acc: 0.572, student val loss: 1.401, student val acc: 0.634 (best student val acc: 0.634))
In epoch 40, student train loss: 1.462, student train acc: 0.575, student val loss: 1.308, student val acc: 0.635 (best student val acc: 0.635))
In epoch 60, student train loss: 1.268, student train acc: 0.614, student val loss: 1.174, student val acc: 0.655 (best student val acc: 0.655))
In epoch 80, student train loss: 1.138, student train acc: 0.658, student val loss: 1.069, student val acc: 0.684 (best student val acc: 0.684))
   RES
541940
1670191382.729971016
   RES
541956
1670191382.883416971
=================
Namespace(gnn='GCN', k=10, i=10, dataset='arxiv', heads=3, dropout=0.25, no_cuda=False, student_only='n', compression_rate='Big')
training configuration:
Model:  GCN
Number of partitions: 10
Dataset: arxiv
num_heads:  3
cpu
# teacher params 21672
# student params 10856
In epoch 0, train loss: 3.722, train acc: 0.008, val loss: 3.715, val acc: 0.002 (best val acc: 0.002))
In epoch 20, train loss: 2.198, train acc: 0.451, val loss: 2.265, val acc: 0.445 (best val acc: 0.445))
In epoch 40, train loss: 1.640, train acc: 0.574, val loss: 1.762, val acc: 0.539 (best val acc: 0.539))
In epoch 60, train loss: 1.418, train acc: 0.611, val loss: 1.545, val acc: 0.561 (best val acc: 0.563))
In epoch 80, train loss: 1.302, train acc: 0.637, val loss: 1.431, val acc: 0.582 (best val acc: 0.582))
In epoch 0, student train loss: 3.306, student train acc: 0.009, student val loss: 3.295, student val acc: 0.005 (best student val acc: 0.005))
In epoch 20, student train loss: 2.216, student train acc: 0.360, student val loss: 2.240, student val acc: 0.363 (best student val acc: 0.366))
In epoch 40, student train loss: 1.730, student train acc: 0.504, student val loss: 1.808, student val acc: 0.499 (best student val acc: 0.499))
In epoch 60, student train loss: 1.447, student train acc: 0.574, student val loss: 1.548, student val acc: 0.541 (best student val acc: 0.541))
In epoch 80, student train loss: 1.300, student train acc: 0.607, student val loss: 1.414, student val acc: 0.556 (best student val acc: 0.556))
   RES
533404
1670191383.036719466
   RES
1670191383.191962997
1670191383.195323500
1670191383.196840390
