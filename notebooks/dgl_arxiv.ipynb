{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "from ogb.nodeproppred import DglNodePropPredDataset\n",
    "import networkx as nx\n",
    "import metis\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import GraphConv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Cora Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DglNodePropPredDataset('ogbn-arxiv')\n",
    "arxiv_dgl = dgl.data.AsNodePredDataset(dataset)[0]\n",
    "arxiv_dgl = dgl.add_reverse_edges(arxiv_dgl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to a networkx graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_nx = dgl.to_networkx(arxiv_dgl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METIS Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=4\n",
    "_, parts = metis.part_graph(arxiv_nx,k,contig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_tensor = torch.Tensor(parts)\n",
    "sgs = []\n",
    "\n",
    "# for each partition\n",
    "for i in range(k):\n",
    "    # get the nodes ids for the partition\n",
    "    sg_nodes = (parts_tensor == i).nonzero()[:,0].tolist()\n",
    "\n",
    "    # get the dgl subgraph from these ids\n",
    "    sg = dgl.node_subgraph(arxiv_dgl, sg_nodes)\n",
    "    sg.ndata['og_ids'] = torch.LongTensor(sg_nodes)\n",
    "    sgs.append(sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the og ids of the nodes that become disconnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ids = (sgs[0].in_degrees() == 0).nonzero()\n",
    "node_ids = sgs[0].ndata['og_ids'][node_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 1), dtype=torch.int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confirm that their neighbors have a different partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proposed solution is to just reconnect the nodes to its old neighbors so will be part of the correct partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sg in sgs:\n",
    "#     node_ids = (sgs[0].in_degrees() == 0).nonzero()\n",
    "#     node_ids = sgs[0].ndata['og_ids'][node_ids]\n",
    "#     for node in node_ids:\n",
    "#         # get the partition of its neighbor\n",
    "#         neighbor = arxiv_nx.neighbors(node)\n",
    "#         neighbor_part = parts_tensor(neighbor)\n",
    "\n",
    "#         # move the node to this partition and add an edge\n",
    "#         sg.remove_nodes(node)\n",
    "#         sgs[neighbor_part].add_node(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts_tensor[46080]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46080]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(arxiv_nx.neighbors(763))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_dgl.in_degrees()[node_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts_tensor[node_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary that maps node ids to partition ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_dict = {}\n",
    "for id,part_id in enumerate(parts):\n",
    "    part_dict[id] = part_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label the nodes with their partition id and save to visualize in Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(cora_c_nx,part_dict,name=\"partition\")\n",
    "nx.write_gexf(cora_c_nx,\"dgl_cora_connected_parts.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get node ids for each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_tensor = torch.Tensor(parts)\n",
    "sg0_nodes = (parts_tensor == 0).nonzero()[:,0].tolist()\n",
    "sg1_nodes = (parts_tensor == 1).nonzero()[:,0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DGL subgraphs using partition list. This splits all the node features as well which is very conveniant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg0 = dgl.node_subgraph(cora_dgl, sg0_nodes)\n",
    "sg1 = dgl.node_subgraph(cora_dgl, sg1_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sg0 test: tensor(437)\n",
      "sg0 val: tensor(213)\n",
      "sg0 train: tensor(64)\n",
      "sg1 test: tensor(478)\n",
      "sg1 val: tensor(246)\n",
      "sg1 train: tensor(58)\n"
     ]
    }
   ],
   "source": [
    "print(\"sg0 test:\",sum(sg0.ndata['test_mask']==True))\n",
    "print(\"sg0 val:\",sum(sg0.ndata['val_mask']==True))\n",
    "print(\"sg0 train:\",sum(sg0.ndata['train_mask']==True))\n",
    "print(\"sg1 test:\",sum(sg1.ndata['test_mask']==True))\n",
    "print(\"sg1 val:\",sum(sg1.ndata['val_mask']==True))\n",
    "print(\"sg1 train:\",sum(sg1.ndata['train_mask']==True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    for e in range(100):\n",
    "        # Forward\n",
    "        logits = model(g, features)\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that you should only compute the losses of the nodes in the training set.\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
    "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(cora_dgl.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
    "model0 = GCN(sg0.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
    "model1 = GCN(sg1.ndata['feat'].shape[1], 16, dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1.946, val acc: 0.118 (best 0.118), test acc: 0.131 (best 0.131)\n",
      "In epoch 5, loss: 1.888, val acc: 0.268 (best 0.268), test acc: 0.293 (best 0.293)\n",
      "In epoch 10, loss: 1.806, val acc: 0.314 (best 0.314), test acc: 0.342 (best 0.342)\n",
      "In epoch 15, loss: 1.703, val acc: 0.436 (best 0.436), test acc: 0.478 (best 0.478)\n",
      "In epoch 20, loss: 1.579, val acc: 0.584 (best 0.584), test acc: 0.593 (best 0.593)\n",
      "In epoch 25, loss: 1.434, val acc: 0.675 (best 0.675), test acc: 0.674 (best 0.674)\n",
      "In epoch 30, loss: 1.274, val acc: 0.717 (best 0.717), test acc: 0.718 (best 0.718)\n",
      "In epoch 35, loss: 1.104, val acc: 0.732 (best 0.732), test acc: 0.739 (best 0.739)\n",
      "In epoch 40, loss: 0.935, val acc: 0.752 (best 0.752), test acc: 0.741 (best 0.741)\n",
      "In epoch 45, loss: 0.774, val acc: 0.760 (best 0.763), test acc: 0.751 (best 0.750)\n",
      "In epoch 50, loss: 0.631, val acc: 0.769 (best 0.769), test acc: 0.757 (best 0.755)\n",
      "In epoch 55, loss: 0.508, val acc: 0.769 (best 0.771), test acc: 0.756 (best 0.758)\n",
      "In epoch 60, loss: 0.408, val acc: 0.769 (best 0.771), test acc: 0.765 (best 0.758)\n",
      "In epoch 65, loss: 0.328, val acc: 0.771 (best 0.771), test acc: 0.763 (best 0.758)\n",
      "In epoch 70, loss: 0.265, val acc: 0.780 (best 0.780), test acc: 0.767 (best 0.767)\n",
      "In epoch 75, loss: 0.216, val acc: 0.782 (best 0.782), test acc: 0.769 (best 0.767)\n",
      "In epoch 80, loss: 0.177, val acc: 0.782 (best 0.782), test acc: 0.773 (best 0.767)\n",
      "In epoch 85, loss: 0.147, val acc: 0.786 (best 0.786), test acc: 0.772 (best 0.772)\n",
      "In epoch 90, loss: 0.124, val acc: 0.784 (best 0.786), test acc: 0.773 (best 0.772)\n",
      "In epoch 95, loss: 0.105, val acc: 0.784 (best 0.786), test acc: 0.774 (best 0.772)\n"
     ]
    }
   ],
   "source": [
    "train(cora_dgl,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1.945, val acc: 0.155 (best 0.155), test acc: 0.140 (best 0.140)\n",
      "In epoch 5, loss: 1.810, val acc: 0.385 (best 0.394), test acc: 0.398 (best 0.405)\n",
      "In epoch 10, loss: 1.647, val acc: 0.347 (best 0.394), test acc: 0.366 (best 0.405)\n",
      "In epoch 15, loss: 1.488, val acc: 0.347 (best 0.394), test acc: 0.362 (best 0.405)\n",
      "In epoch 20, loss: 1.333, val acc: 0.371 (best 0.394), test acc: 0.378 (best 0.405)\n",
      "In epoch 25, loss: 1.172, val acc: 0.394 (best 0.394), test acc: 0.437 (best 0.405)\n",
      "In epoch 30, loss: 1.009, val acc: 0.521 (best 0.521), test acc: 0.503 (best 0.503)\n",
      "In epoch 35, loss: 0.851, val acc: 0.563 (best 0.563), test acc: 0.542 (best 0.542)\n",
      "In epoch 40, loss: 0.705, val acc: 0.596 (best 0.596), test acc: 0.565 (best 0.563)\n",
      "In epoch 45, loss: 0.577, val acc: 0.606 (best 0.606), test acc: 0.616 (best 0.586)\n",
      "In epoch 50, loss: 0.467, val acc: 0.629 (best 0.629), test acc: 0.638 (best 0.636)\n",
      "In epoch 55, loss: 0.376, val acc: 0.648 (best 0.648), test acc: 0.638 (best 0.638)\n",
      "In epoch 60, loss: 0.301, val acc: 0.653 (best 0.653), test acc: 0.643 (best 0.641)\n",
      "In epoch 65, loss: 0.241, val acc: 0.667 (best 0.667), test acc: 0.645 (best 0.645)\n",
      "In epoch 70, loss: 0.192, val acc: 0.671 (best 0.671), test acc: 0.654 (best 0.654)\n",
      "In epoch 75, loss: 0.154, val acc: 0.676 (best 0.676), test acc: 0.659 (best 0.654)\n",
      "In epoch 80, loss: 0.125, val acc: 0.676 (best 0.676), test acc: 0.673 (best 0.654)\n",
      "In epoch 85, loss: 0.102, val acc: 0.676 (best 0.676), test acc: 0.673 (best 0.654)\n",
      "In epoch 90, loss: 0.084, val acc: 0.676 (best 0.676), test acc: 0.666 (best 0.654)\n",
      "In epoch 95, loss: 0.071, val acc: 0.676 (best 0.676), test acc: 0.666 (best 0.654)\n"
     ]
    }
   ],
   "source": [
    "train(sg0, model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1.948, val acc: 0.041 (best 0.041), test acc: 0.033 (best 0.033)\n",
      "In epoch 5, loss: 1.871, val acc: 0.366 (best 0.435), test acc: 0.431 (best 0.458)\n",
      "In epoch 10, loss: 1.781, val acc: 0.402 (best 0.435), test acc: 0.458 (best 0.458)\n",
      "In epoch 15, loss: 1.676, val acc: 0.423 (best 0.435), test acc: 0.464 (best 0.458)\n",
      "In epoch 20, loss: 1.563, val acc: 0.244 (best 0.435), test acc: 0.318 (best 0.458)\n",
      "In epoch 25, loss: 1.450, val acc: 0.171 (best 0.435), test acc: 0.243 (best 0.458)\n",
      "In epoch 30, loss: 1.342, val acc: 0.175 (best 0.435), test acc: 0.243 (best 0.458)\n",
      "In epoch 35, loss: 1.239, val acc: 0.244 (best 0.435), test acc: 0.318 (best 0.458)\n",
      "In epoch 40, loss: 1.143, val acc: 0.333 (best 0.435), test acc: 0.372 (best 0.458)\n",
      "In epoch 45, loss: 1.053, val acc: 0.398 (best 0.435), test acc: 0.444 (best 0.458)\n",
      "In epoch 50, loss: 0.971, val acc: 0.476 (best 0.476), test acc: 0.498 (best 0.498)\n",
      "In epoch 55, loss: 0.894, val acc: 0.545 (best 0.545), test acc: 0.559 (best 0.559)\n",
      "In epoch 60, loss: 0.822, val acc: 0.671 (best 0.671), test acc: 0.632 (best 0.632)\n",
      "In epoch 65, loss: 0.752, val acc: 0.728 (best 0.728), test acc: 0.690 (best 0.690)\n",
      "In epoch 70, loss: 0.683, val acc: 0.764 (best 0.764), test acc: 0.734 (best 0.734)\n",
      "In epoch 75, loss: 0.614, val acc: 0.772 (best 0.772), test acc: 0.755 (best 0.749)\n",
      "In epoch 80, loss: 0.545, val acc: 0.776 (best 0.785), test acc: 0.778 (best 0.776)\n",
      "In epoch 85, loss: 0.476, val acc: 0.789 (best 0.789), test acc: 0.782 (best 0.787)\n",
      "In epoch 90, loss: 0.410, val acc: 0.789 (best 0.793), test acc: 0.787 (best 0.780)\n",
      "In epoch 95, loss: 0.349, val acc: 0.797 (best 0.797), test acc: 0.797 (best 0.797)\n"
     ]
    }
   ],
   "source": [
    "train(sg1, model1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('rwn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb836cccf733935fd1764337262ee34c87745a1ee81a013fe4ba29a11dcb5f0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
